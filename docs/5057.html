<html>
<head>
<title>Image classification tutorials in pytorch-transfer learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">pytorch中的图像分类教程-迁移学习</h1>
<blockquote>原文：<a href="https://medium.com/swlh/image-classification-tutorials-in-pytorch-transfer-learning-19ebc329e200#2019-06-07">https://medium.com/swlh/image-classification-tutorials-in-pytorch-transfer-learning-19ebc329e200#2019-06-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8a47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">报名参加我的计算机视觉直播课程:<a class="ae jd" href="https://bit.ly/cv_coursem" rel="noopener ugc nofollow" target="_blank">https://bit.ly/cv_coursem</a></p><p id="27ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图像分类是机器学习/深度学习的任务，其中我们基于特定类别的人类标记数据对图像进行分类。我们将卷积神经网络用于图像数据，pytorch的torchvision框架中内置了各种良好的预训练架构。我们将使用最近发布的<a class="ae jd" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">高效网</a>，因为它给出了最好的精确度。这里给出了它在pytorch中的实现<a class="ae jd" href="https://github.com/lukemelas/EfficientNet-PyTorch" rel="noopener ugc nofollow" target="_blank">。我将尝试用数据分析、误差图、混淆矩阵等来完成这篇文章。本文的Github库是这里的</a><a class="ae jd" href="https://github.com/sanchit2843/MLBasics/tree/master/IntelClassificationKaggle" rel="noopener ugc nofollow" target="_blank"/>。我们将使用<a class="ae jd" href="https://www.kaggle.com/puneet6060/intel-image-classification" rel="noopener ugc nofollow" target="_blank"> kaggle </a>上提供的英特尔场景分类数据。此处链接笔记本<a class="ae jd" href="https://colab.research.google.com/github/sanchit2843/MLBasics/blob/master/IntelClassificationKaggle/Pytorch%20transfer%20learning%20tutorial%20%5B93%25acc%5D.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="e69c" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">数据加载器</h1><p id="e585" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">在图像数据中，数据足够大，我们无法在内存中加载完整的数据，因此我们需要制作dataloader，它将在我们传递数据时加载图像，并且只在内存中加载少量图像(内存中加载的图像数量是批量大小)。要制作数据加载器，我们要么需要将我们的图像划分到数据集中每个类的文件夹中，要么如果我们有所有图像的名称及其相应的标签，那么我们需要制作一个自定义数据集类，然后制作一个数据加载器。我们的数据集已经存在于不同的文件夹中，所以我使用了第一种方法。要查看第二种方法的示例，请单击<a class="ae jd" href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" rel="noopener ugc nofollow" target="_blank">此处</a>，上面链接中的“FaceLandmarksDataset”类是自定义数据集类。有关基本解释，请参见代码中的注释。数据集文件夹包含每个类的6个子文件夹。我还将测试数据分为有效和测试两部分。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kh"><img src="../Images/66e8690e17732bc644912cacf28aefa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*SI4LEcERFtrkKZjibvN0KA.png"/></div></figure><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="9d7f" class="ku jf hi kq b fi kv kw l kx ky">#We need to pass path to folder containing folders of classes</span><span id="d5dd" class="ku jf hi kq b fi kz kw l kx ky">train_data = torchvision.datasets.ImageFolder(root = '../input/seg_train/seg_train', transform = train_transforms)</span><span id="e4ba" class="ku jf hi kq b fi kz kw l kx ky">test_data = torchvision.datasets.ImageFolder(root = '../input/seg_test/seg_test', transform = test_transforms)</span><span id="653d" class="ku jf hi kq b fi kz kw l kx ky">def data_loader(train_data,test_data = None , valid_size = None , batch_size = 32):<br/>    train_loader =  DataLoader(train_data, batch_size = batch_size , shuffle = True)<br/>    if(test_data == None and valid_size == None):<br/>        dataloaders = {'train':train_loader}<br/>        return dataloaders<br/>    if(test_data == None and valid_size!=None):<br/>        data_len = len(train_data)<br/>        indices = list(range(data_len))<br/>        np.random.shuffle(indices)<br/>        split1 = int(np.floor(valid_size * data_len))<br/>        valid_idx , test_idx = indices[:split1], indices[split1:]<br/>        valid_sampler = SubsetRandomSampler(valid_idx)<br/>        valid_loader = DataLoader(train_data, batch_size= batch_size, sampler=valid_sampler)<br/>        dataloaders = {'train':train_loader,'val':valid_loader}<br/>        return dataloaders<br/>    if(test_data != None and valid_size!=None):<br/>        data_len = len(test_data)<br/>        indices = list(range(data_len))<br/>        np.random.shuffle(indices)<br/>        split1 = int(np.floor(valid_size * data_len))<br/>        valid_idx , test_idx = indices[:split1], indices[split1:]<br/>        valid_sampler = SubsetRandomSampler(valid_idx)<br/>        test_sampler = SubsetRandomSampler(test_idx)<br/>        valid_loader = DataLoader(test_data, batch_size= batch_size, sampler=valid_sampler)<br/>        test_loader = DataLoader(test_data, batch_size= batch_size, sampler=test_sampler)<br/>        dataloaders = {'train':train_loader,'val':valid_loader,'test':test_loader}<br/>        return dataloaders</span></pre><p id="dffb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，函数data_loader将把train_data、test_data作为输入。我们还可以使用valid_size创建一个验证分割。它将返回一个包含所有已定义的数据加载器的字典。它可以用作</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="52ca" class="ku jf hi kq b fi kv kw l kx ky">dataloaders = data_loader(train_data,test_data , valid_size = 0.2 , batch_size = batch_size)</span></pre><p id="310a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还定义了train_transforms。这是您想要在数据集上应用的数据扩充技术的列表。如果你不想要任何数据增强，它可以包含调整图像大小的功能，并将其转换为pytorch张量，我们需要在输入到神经网络之前。使用图像增强最有益，因此我将其声明为:</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="ce33" class="ku jf hi kq b fi kv kw l kx ky">im_size = 150<br/>train_transforms = transforms.Compose([<br/>                            transforms.Resize((im_size,im_size)),<br/>        transforms.RandomResizedCrop(size=315, scale=(0.95, 1.0)),                                   transforms.RandomRotation(degrees=10),                                   transforms.RandomHorizontalFlip(),<br/>transforms.CenterCrop(size=299), # Image net standards<br/>transforms.ToTensor(),                                        transforms.Normalize((0.4302, 0.4575, 0.4539), (0.2361, 0.2347, 0.2432))])</span></pre><p id="812e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入归一化函数(<em class="la">转换)的平均值和标准偏差。Normalize((0.4302，0.4575，0.4539)，(0.2361，0.2347，0.2432))] </em>))也可以设置为0.5但最好是求数据集的均值和标准差。可以使用以下公式为您的自定义数据集计算该值:</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="6248" class="ku jf hi kq b fi kv kw l kx ky">mean = 0.<br/>std = 0.<br/>nb_samples = len(data)<br/>for data,_ in dataloader:<br/>    batch_samples = data.size(0)<br/>    data = data.view(batch_samples, data.size(1), -1)<br/>    mean += data.mean(2).sum(0)<br/>    std += data.std(2).sum(0)<br/>mean /= nb_samples<br/>std /= nb_samples</span></pre></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="5a54" class="je jf hi bd jg jh li jj jk jl lj jn jo jp lk jr js jt ll jv jw jx lm jz ka kb bi translated">数据分析</h1><p id="29b1" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">我们需要用这些特定的类来可视化数据集，这段代码将有助于可视化这些类。我们可以获得数据集类名称，如下所示:</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="66b9" class="ku jf hi kq b fi kv kw l kx ky">classes = train_data.classes</span></pre><p id="5698" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过对类进行编码和解码，我们可以很容易地找到标签。</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="da8e" class="ku jf hi kq b fi kv kw l kx ky">#encoder and decoder to convert classes into integer<br/>decoder = {}<br/>for i in range(len(classes)):<br/>    decoder[classes[i]] = i<br/>encoder = {}<br/>for i in range(len(classes)):<br/>    encoder[i] = classes[i]</span></pre><p id="7137" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这段代码将可视化n_figures数字与有特定的类。</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="2739" class="ku jf hi kq b fi kv kw l kx ky">import matplotlib.pyplot as plt<br/>import random<br/>#plotting rondom images from dataset<br/>def class_plot( data , encoder ,inv_normalizen_figures = 12):<br/>    n_row = int(n_figures/3)<br/>    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=3)<br/>    for ax in axes.flatten():<br/>        a = random.randint(0,len(data))<br/>        (image,label) = data[a]<br/>        label = int(label)<br/>        l = encoder[label]<br/>        image = inv_normalize(image)<br/>        image = image.numpy().transpose(1,2,0)<br/>        im = ax.imshow(image)<br/>        ax.set_title(l)<br/>        ax.axis('off')<br/>    plt.show()<br/>class_plot(train_data,encoder,inv_normalize)</span></pre><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/a5a77e4ca9712f7d7b506819600efe3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xZ7U1AqDxZIt4QIU07k6ZA.png"/></div></div></figure><p id="cdda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们使用了inv_normalize。它在我们已经标准化原始图像的情况下使用。在可视化之前，我们需要对图像进行逆归一化。我们可以使用相同的transform.normalize()来定义inv_normalize。平均值和标准偏差的值将改变为:</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="f9b6" class="ku jf hi kq b fi kv kw l kx ky">inv_normalize =  transforms.Normalize(<br/>    mean=[-0.4302/0.2361, -0.4575/0.2347, -0.4539/0.2432],<br/>    std=[1/0.2361, 1/0.2347, 1/0.2432]<br/>)</span></pre></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="54a7" class="je jf hi bd jg jh li jj jk jl lj jn jo jp lk jr js jt ll jv jw jx lm jz ka kb bi translated">模型</h1><p id="8641" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">如前所述，我使用了高效网络。如果您想使用pytorch中给出的模型，只需将第4行替换为</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="154b" class="ku jf hi kq b fi kv kw l kx ky">self.resnet = models.resnet34(pretrained = <strong class="kq ls">True</strong>)</span></pre><p id="ee59" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将使该型号成为resnet34，pytorch中的其他型号可以在<a class="ae jd" href="https://pytorch.org/docs/stable/torchvision/models.html." rel="noopener ugc nofollow" target="_blank">这里</a>看到。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="f3b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们创建了一个自定义的神经网络类。</p><p id="631f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于分类，我们使用交叉熵损失。我们也可以使用负对数似然损失，但我们需要神经网络的输出是log softmax。</p></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="749e" class="je jf hi bd jg jh li jj jk jl lj jn jo jp lk jr js jt ll jv jw jx lm jz ka kb bi translated">培养</h1><p id="fd8a" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">为了找到学习率，我使用了快速人工智能课程中建议的学习率计划程序。对于pytorch，我使用了在<a class="ae jd" href="https://github.com/davidtvs/pytorch-lr-finder" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上可用的实现。</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="117d" class="ku jf hi kq b fi kv kw l kx ky">from lr_finder import LRFinder<br/>optimizer_ft = optim.Adam(classifier.parameters(), lr=0.0000001)<br/>lr_finder = LRFinder(classifier, optimizer_ft, criterion, device=device)<br/>lr_finder.range_test(train_loader, end_lr=1, num_iter=500)<br/>lr_finder.reset()<br/>lr_finder.plot()</span></pre><p id="364a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将为我们提供损失-时期图，并且我们可以找到模型将继续更快收敛的最大学习速率。为了减少过度拟合，我还使用了早期停止，这在<a class="ae jd" href="https://github.com/Bjarten/early-stopping-pytorch" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的pytorch中可用。提前停止将基于验证损失停止模型。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lt lu l"/></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lv"><img src="../Images/acb6975ec0c166fc46a86ac143898913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*NtRfB75mii-iqCnc4vj8_g.png"/></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lv"><img src="../Images/f0ea935ec6c14266d70afef5c168f9cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*tzmMzi0a2MmFK4hl-7YWSQ.png"/></div></figure></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="4593" class="je jf hi bd jg jh li jj jk jl lj jn jo jp lk jr js jt ll jv jw jx lm jz ka kb bi translated">测试和性能指标:</h1><p id="397f" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">为了检查模型的性能，我们需要从数据的测试分割中获得预测。下面的函数将把testloader和modelas作为一个参数，并将返回错误预测的预测标签、真实标签、真实和预测标签以及错误预测的图像列表。创建的错误预测列表将帮助我们绘制带有错误预测的图像。</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="8cf6" class="ku jf hi kq b fi kv kw l kx ky">batch_size = 8<br/>sm = nn.Softmax(dim = 1)<br/>def test(model,dataloader):<br/>    running_corrects = 0<br/>    running_loss=0<br/>    pred = []<br/>    true = []<br/>    pred_wrong = []<br/>    true_wrong = []<br/>    image = []<br/>    <br/>    for batch_idx, (data, target) in enumerate(dataloader):<br/>        data, target = Variable(data), Variable(target)<br/>        data = data.type(torch.cuda.FloatTensor)<br/>        target = target.type(torch.cuda.LongTensor)<br/>        model.eval()<br/>        output = model(data)<br/>        loss = criterion(output, target)<br/>        output = sm(output)<br/>        _, preds = torch.max(output, 1)<br/>        running_corrects = running_corrects + torch.sum(preds == target.data)<br/>        running_loss += loss.item() * data.size(0)<br/>        preds = preds.cpu().numpy()<br/>        target = target.cpu().numpy()<br/>        preds = np.reshape(preds,(len(preds),1))<br/>        target = np.reshape(target,(len(preds),1))<br/>        data = data.cpu().numpy()<br/>        <br/>        for i in range(len(preds)):<br/>            pred.append(preds[i])<br/>            true.append(target[i])<br/>            if(preds[i]!=target[i]):<br/>                pred_wrong.append(preds[i])<br/>                true_wrong.append(target[i])<br/>                image.append(data[i])<br/>      <br/>    epoch_acc = running_corrects.double()/(len(dataloader)*batch_size)<br/>    epoch_loss = running_loss/(len(dataloader)*batch_size)<br/>    print(epoch_acc,epoch_loss)<br/>    return true,pred,image,true_wrong,pred_wrong</span></pre><p id="2fd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们可以使用代码绘制带有错误预测的图像。它将把上述函数返回的true _ wrong、pred _ wrong和image作为输入。它还将采用上面定义的inv_normalize。</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="d9ff" class="ku jf hi kq b fi kv kw l kx ky">def wrong_plot(true,ima,pred,encoder,inv_normalize,n_figures = 12):<br/>    print('Classes in order Actual and Predicted')<br/>    n_row = int(n_figures/3)<br/>    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=3)<br/>    for ax in axes.flatten():<br/>        a = random.randint(0,len(true)-1)<br/>    <br/>        image,correct,wrong = ima[a],true[a],pred[a]<br/>        image = torch.from_numpy(image)<br/>        correct = int(correct)<br/>        c = encoder[correct]<br/>        wrong = int(wrong)<br/>        w = encoder[wrong]<br/>        f = 'A:'+c + ',' +'P:'+w<br/>        if inv_normalize !=None:<br/>            image = inv_normalize(image)<br/>        image = image.numpy().transpose(1,2,0)<br/>        im = ax.imshow(image)<br/>        ax.set_title(f)<br/>        ax.axis('off')<br/>    plt.show()</span></pre><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lw"><img src="../Images/cf38cdb36e86fd231eaf337d6f28cf2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*50hpW4jDGV5N2Eb9htV8Ig.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">wrong predictions</figcaption></figure><p id="b373" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将使用各种性能指标来检查模型的性能，如准确性、f1分数、精确度和召回率。我们还将绘制预测的混淆矩阵。</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="3b7b" class="ku jf hi kq b fi kv kw l kx ky">def performance_matrix(true,pred):<br/>    precision = metrics.precision_score(true,pred,average='macro')<br/>    recall = metrics.recall_score(true,pred,average='macro')<br/>    accuracy = metrics.accuracy_score(true,pred)<br/>    f1_score = metrics.f1_score(true,pred,average='macro')<br/>    print('Confusion Matrix:\n',metrics.confusion_matrix(true, pred))<br/>    print('Precision: {} Recall: {}, Accuracy: {}: ,f1_score: {}'.format(precision*100,recall*100,accuracy*100,f1_score*100))</span></pre><p id="c2c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果:</p><p id="1246" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准确率:90.78，召回率:90.68，准确率:90.33，f1_score: 90.44</p><p id="e1fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">混淆矩阵:</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es mb"><img src="../Images/95eaa475ee847e6f3a9e4ab187f1cd9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*nl5_4G34XWr8pgTfTl8SeQ.png"/></div></figure><p id="f036" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要绘制这种类型的图像，请使用以下代码:</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="cc5c" class="ku jf hi kq b fi kv kw l kx ky">def plot_confusion_matrix(y_true, y_pred, classes,<br/>                          normalize=False,<br/>                          title=None,<br/>                          cmap=plt.cm.Blues):<br/>    """<br/>    This function prints and plots the confusion matrix.<br/>    Normalization can be applied by setting `normalize=True`.<br/>    """<br/>    if not title:<br/>        if normalize:<br/>            title = 'Normalized confusion matrix'<br/>        else:<br/>            title = 'Confusion matrix, without normalization'</span><span id="c1a3" class="ku jf hi kq b fi kz kw l kx ky"># Compute confusion matrix<br/>    cm = metrics.confusion_matrix(y_true, y_pred)<br/>    # Only use the labels that appear in the data<br/>    #classes = classes[unique_labels(y_true, y_pred)]<br/>    if normalize:<br/>        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]<br/>        print("Normalized confusion matrix")<br/>    else:<br/>        print('Confusion matrix, without normalization')</span><span id="b05a" class="ku jf hi kq b fi kz kw l kx ky">print(cm)</span><span id="2d6c" class="ku jf hi kq b fi kz kw l kx ky">fig, ax = plt.subplots()<br/>    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)<br/>    ax.figure.colorbar(im, ax=ax)<br/>    # We want to show all ticks...<br/>    ax.set(xticks=np.arange(cm.shape[1]),<br/>           yticks=np.arange(cm.shape[0]),<br/>           # ... and label them with the respective list entries<br/>           xticklabels=classes, yticklabels=classes,<br/>           title=title,<br/>           ylabel='True label',<br/>           xlabel='Predicted label')</span><span id="8acc" class="ku jf hi kq b fi kz kw l kx ky"># Rotate the tick labels and set their alignment.<br/>    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",<br/>             rotation_mode="anchor")</span><span id="c0d5" class="ku jf hi kq b fi kz kw l kx ky"># Loop over data dimensions and create text annotations.<br/>    fmt = '.2f' if normalize else 'd'<br/>    thresh = cm.max() / 2.<br/>    for i in range(cm.shape[0]):<br/>        for j in range(cm.shape[1]):<br/>            ax.text(j, i, format(cm[i, j], fmt),<br/>                    ha="center", va="center",<br/>                    color="white" if cm[i, j] &gt; thresh else "black")<br/>    fig.tight_layout()<br/>    return ax<br/>plot_confusion_matrix(true, pred, classes= classes,title='Confusion matrix, without normalization')</span></pre><p id="7d55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该函数将真实标签和预测标签作为输入。它还将接受类名作为输入。</p><p id="5361" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih ls">预测:</strong></p><p id="8db5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，可以作为应用程序部署的最终分类模型应该对单个图像进行预测，并给出最高预测类别的置信度得分。</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="dfba" class="ku jf hi kq b fi kv kw l kx ky">def predict(model,image,device,encoder,transforms = None,inv_normalize = None):<br/>    #model = torch.load('./model.h5')<br/>    model.eval()<br/>    if(isinstance(image,np.ndarray)):<br/>      image = Image.fromarray(image)<br/>    if(transforms!=None):<br/>        image = transforms(image)<br/>    data = image.expand(1,-1,-1,-1)<br/>    data = data.type(torch.FloatTensor).to(device)<br/>    sm = nn.Softmax(dim = 1)<br/>    output = model(data)<br/>    output = sm(output)<br/>    _, preds = torch.max(output, 1)<br/>    img_plot(image,inv_normalize)<br/>    prediction_bar(output,encoder)<br/>    return preds</span></pre><p id="3d8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个函数将获取运行系统的设备(CPU或GPU)的映像。之前定义的编码器、测试转换和inv_normalize。它将给出前5个类的置信度得分，并绘制置信度得分的条形图。使用的img_plot和预测条函数定义如下:</p><pre class="ki kj kk kl fd kp kq kr ks aw kt bi"><span id="5be0" class="ku jf hi kq b fi kv kw l kx ky">def prediction_bar(output,encoder):<br/>    output = output.cpu().detach().numpy()<br/>    a = output.argsort()<br/>    a = a[0]<br/>    <br/>    size = len(a)<br/>    if(size&gt;5):<br/>        a = np.flip(a[-5:])<br/>    else:<br/>        a = np.flip(a[-1*size:])<br/>    prediction = list()<br/>    clas = list()<br/>    for i in a:<br/>      prediction.append(float(output[:,i]*100))<br/>      clas.append(str(i))<br/>    for i in a:<br/>        print('Class: {} , confidence: {}'.format(encoder[int(i)],float(output[:,i]*100)))<br/>    plt.bar(clas,prediction)</span><span id="291e" class="ku jf hi kq b fi kz kw l kx ky">def img_plot(image,inv_normalize = None):<br/>    if(inv_normalize!=None):<br/>        image = inv_normalize(image)<br/>    image = image.cpu().numpy().transpose(1,2,0)<br/>    plt.imshow(image)<br/>    plt.show()</span></pre><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mc"><img src="../Images/a1a8d0ee814ef81658082fe25fd35684.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FmCVdFzIOsS92MlytijPkQ.png"/></div></div></figure><p id="b17d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你遇到错误，请查看google colab上的笔记本，并尝试执行代码。</p><p id="9dcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您阅读完整的博客。如果我做错了什么，请批评。</p></div></div>    
</body>
</html>