<html>
<head>
<title>Designing AI Policy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">设计人工智能策略</h1>
<blockquote>原文：<a href="https://medium.com/swlh/ai-policy-design-dd177f534329?source=collection_archive---------101-----------------------#2019-06-03">https://medium.com/swlh/ai-policy-design-dd177f534329?source=collection_archive---------101-----------------------#2019-06-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="746a" class="pw-subtitle-paragraph ig hh hi bd b ih ii ij ik il im in io ip iq ir is it iu iv iw ix dx translated">以及智能机器的社会影响</h2></div><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es iy"><img src="../Images/8338abf4a3459f0bda0e5efd41cd41fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*f_LFmBOQUPc3XSyM"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx">Photo by <a class="ae jo" href="https://unsplash.com/@alinnnaaaa?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alina Grubnyak</a> on <a class="ae jo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="db62" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">人工智能给政策设计者带来了巨大的挑战。在当代文化中，智能机器的幽灵萦绕在求职者、科学家和实业家的脑海中。简单的推文或《纽约客》杂志的曝光中包含着对谁将管理和部署大数据集或自我学习神经网络所提供的杠杆作用的焦虑；人工智能破坏地球的生物量是新的核冬天场景——只是击败超级细菌和外星人入侵。然而，与我们遥远的命运相去甚远的是现实的日常问题，包括劳动力市场失调、人口歧视、武器化和许多其他关键领域。</p><p id="00e6" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">本文试图关注人类活动的几个领域，这些领域将受到工业规模人工智能的重大影响，以及随着这些新技术渗透到公共和私人生活中，政策制定者将面临的困难。从无人驾驶运输卡车到芝加哥犯罪热图，甚至是用无人驾驶飞机瞄准恐怖分子，所有这些都提出了没有明确答案的紧迫问题。此外，我们对世界末日情景的执着在多大程度上伤害或帮助了公众对实质性政策问题的参与？这项分析着眼于几个因素及其在政策设计和人工智能领域的作用。</p><h1 id="9ac6" class="kl km hi bd kn ko kp kq kr ks kt ku kv ip kw iq kx is ky it kz iv la iw lb lc bi translated">聪明的劳动力</h1><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es ld"><img src="../Images/ff0e1999e74f91b1d96139eeea0ed873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DWnlyq_7wRuLQ6avqfE9XQ.jpeg"/></div></div></figure><p id="b6ce" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">在全国众多的州际公路和高速公路中，从俄勒冈到华盛顿和佛罗里达一直到阿巴拉契亚的几条走廊为世界上第一条自动驾驶卡车路线的基础设施提供了支持。使用一系列参数，包括<a class="ae jo" href="https://www.prnewswire.com/news-releases/inrix-identifies-us-corridors-best-suited-for-highly-automated-truck-deployment-300713435.html" rel="noopener ugc nofollow" target="_blank">货运量、交通和其他因素</a>，南部和西北部的特定位置是开发人工智能首次涉足大规模自动驾驶的主要目标。正是这些领域的发展将加速对各种自动驾驶车辆范围的需求，包括<a class="ae jo" href="https://www.youtube.com/watch?v=ZuX5qFdiiI0" rel="noopener ugc nofollow" target="_blank">运输船</a>，货机和最后一英里包裹递送。然而，这一成就是有代价的，那就是冒着数百万蓝领工人失业的风险。这个问题给政策制定者带来了巨大的挑战。如何对数百万工人进行再培训以利用新的机会？这些新机会本身是否有被自学机器人吞噬的风险，这些机器人会钻入白领工作中？</p><p id="4603" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">即使是新闻领域也不能幸免于人工智能自动化。就在最近，英国出版商<a class="ae jo" href="https://www.compelo.com/ai-in-journalism/" rel="noopener ugc nofollow" target="_blank"> Daily Mirror声明他们正在将人工智能</a>整合到他们的报道过程中。这个名为Krzana的mech-journo应用程序在广阔的社交媒体、当地新闻和博客中寻找虚拟空间中涌现的故事。在这种情况下，这可能不是一个直接的替代，但肯定有一种感觉，这些作家正在训练他们的替代品。也许不像卡车司机那样面临同样的直接威胁，但确实有一种不祥的感觉，AI很快就会写文章。也许<a class="ae jo" href="https://www.wired.com/story/googles-learning-software-learns-to-write-learning-software/" rel="noopener ugc nofollow" target="_blank">记者可以接受再培训，然后写代码</a>。</p><p id="a5c9" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">对于政策设计来说，这一点变得很有趣，那就是弄清楚如何对待自主劳动，以便我们仍然关注日常生活中人们的利益和安全。我们不能忘记，随着智能机器人进入越来越多的领域，监管机构以批判的眼光看待机器世界至关重要——可能需要借助工具，在使用高分辨率数据制定政策的领域利用人工智能。无论情况如何，认真考虑智能机器人如何影响工作的时候到了，不管是简单还是复杂。</p><h1 id="24ac" class="kl km hi bd kn ko kp kq kr ks kt ku kv ip kw iq kx is ky it kz iv la iw lb lc bi translated"><em class="if">歧视性数据</em></h1><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es ld"><img src="../Images/7ca9ba1eefd3e879ee6766eba0a968cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uzS5--KxvhUcyC5eLo9eMA.jpeg"/></div></div></figure><p id="b9a9" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">设计的数据是模型中二进制点之间的区别，无论是存储在数据库中的对象，还是通过量化这些对象的累积计算来表示。但在讨论AI背景下的歧视时，我们所谈论的不同于技术定义或专业术语；在智能应用领域，数据必然反映了代码作者所期望的焦点。数据成为用户和服务、生成器和分配器、传感器和服务器之间交换的数字历史。关于智能机器使用数据的政策问题正稳步面对如何使用数据和出于什么目的的始终存在的现实；谁来协商从智能机器获得可操作用途所需的设计逻辑？</p><p id="3e9b" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">值得注意的趋势是建立全面的数据模型，特别是关于试图通过面部识别识别人的人工智能软件。这已经成为一个问题，特别是对于<a class="ae jo" href="https://techcrunch.com/2018/09/18/sen-harris-tells-federal-agencies-to-get-serious-about-facial-recognition-risks/" rel="noopener ugc nofollow" target="_blank">非洲裔美国人来说，他们可能被误认为是零售商店的扒手</a>，这是基于人工智能使用过去违法者的历史记录。即使是罕见的假阳性也可能以普遍的方式对这些群体产生负面影响。作为一项政策，当务之急是对智能机器编码器之间的严格和透明的通信、从传感器捕获的数据以及从算法过程中得出的决策进行编目，以裁定司法的不幸何时何地发生。</p><p id="56db" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">通过认识到人工智能能够犯错误，并且——以其目前的形式——受制于人类操纵的突发奇想和影响，必须有办法弥补导致持续错误的失败。认识到这些错误，理解它们是如何浮出水面的，并鼓励人们努力对抗恶意行为，这不仅是必不可少的，也是工业人工智能获得广泛社会接受所必需的。</p><h1 id="228a" class="kl km hi bd kn ko kp kq kr ks kt ku kv ip kw iq kx is ky it kz iv la iw lb lc bi translated"><em class="if">机器学习大战</em></h1><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es ld"><img src="../Images/9a38b9abab2fe3ff30d481a3991a2ece.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OEwaOTj7bYDrAX5ssTPEWg.jpeg"/></div></div></figure><p id="90f8" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">在战场上，人工智能正逐渐成为军队应对威胁的重要组成部分。智能机器打开了军事领域第三次革命的大门，改变了战场空间，使其包括新形式的自主武器、全谱侦察和预测能力，使战役和任务的精确度远远超过以人为中心的决策。截至本文发表时，<a class="ae jo" href="http://media.hoover.org/sites/default/files/documents/Anderson-Waxman_LawAndEthics_r2_FINAL.pdf" rel="noopener ugc nofollow" target="_blank">近三分之一的飞行美国军用车辆</a>包含远程控制系统——用于着陆和起飞、瞄准或导航。人类官员仍然决定何时发射弹药或释放轰炸载荷，但机器视觉的创新已经达到了即时<a class="ae jo" href="https://www.youtube.com/watch?v=Cgxsv1riJhI" rel="noopener ugc nofollow" target="_blank">根据狭窄的分类识别物体的门槛</a>。问题变成了，我们是把人留在决策循环中，还是一旦<a class="ae jo" href="https://www.youtube.com/watch?v=2FjOE9sbTfs" rel="noopener ugc nofollow" target="_blank">认为只有道德行为者需要时，机器会逐渐执行任务</a>？</p><p id="fcfc" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">在战争中使用人工智能的一个重要方面是平民伤亡。事实上，许多主张禁止自主武器的人担心附带损害，这远远超过了消除威胁带来的任何好处。禁止人工智能在军事上的使用的焦点已经转向建立国际条约，禁止发展用于杀戮的智能系统。但是，认为随着商用传感器和开源算法得到更广泛的应用，那些具有战略利益的国家会避免开发智能武器是天真的。</p><p id="066b" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">政策决策者必须对伦理问题和严酷的现实保持敏锐。自从磨砺岩石以来，武器发展已经成为一种战术优势，而这种优势从未被视为理所当然。现在，显而易见的是，虽然民主社会被迫限制这一领域的技术创新，但显然并非所有利益相关方都将效仿。至关重要的是，发达国家应率先制定全球军事机构将采用的标准；灌输建立在通过战争法建立的惯例基础上的合作。</p></div><div class="ab cl le lf gp lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="hb hc hd he hf"><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es ld"><img src="../Images/909893fc155cee058889e8c2a39651f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hGUK3NfuEkyagzLdbsPzkg.jpeg"/></div></div></figure><p id="526d" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">人工智能需要跨学科的方法来解决问题。没有利益相关者、公民和专业人士的合作和指导，人工智能的算法应用将走上黑市之路。截至今天，中国已经<a class="ae jo" href="http://english.gov.cn/policies/latest_releases/2017/07/20/content_281475742458322.htm" rel="noopener ugc nofollow" target="_blank">致力于在2030年</a>前在人工智能设计和实施领域展开竞争，培训科学家和专业人士，并创造足以支持小型大都市规模的数据中心的硬件。重视领导力和实用性的国家，尤其是美国，有责任不仅在技术前沿，而且在伦理和道德层面进行创新。兑现人工智能的承诺并减轻其潜在的灾难性后果不仅是单个主权国家的挑战，也是所有政府的挑战；实现这些目标需要细致入微、公平和制度化的过程，创造一致和统一的能力来处理思维机器的出现可能带来的无数问题。</p><p id="8800" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">通过分析人工智能的实施和管理中可能出现的所有不同的摩擦向量，我们可以开始构建如何以有利于潜在参与者与自动驾驶汽车、机器人士兵和从微小、无处不在的传感器网络中提取的数据的部署应用进行交互的方式指导开发。通过这些强有力和全面的措施，法院和经营者都可以对问责制进行评估，这有助于改进和无争议地协商同意。</p><p id="39f3" class="pw-post-body-paragraph jp jq hi jr b js jt ik ju jv jw in jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">随着每一天的流逝，无处不在的半意识机器越来越接近现实。想想你的听语音转文本命令的<a class="ae jo" href="https://www.youtube.com/watch?v=rxejJxue2U0" rel="noopener ugc nofollow" target="_blank">手机</a>，等待你召唤的<a class="ae jo" href="https://www.youtube.com/watch?v=nUSbcdv6jBA&amp;feature=youtu.be&amp;t=6m34s" rel="noopener ugc nofollow" target="_blank">亚马逊echo】，或者</a><a class="ae jo" href="https://www.youtube.com/watch?v=tlThdr3O5Qo" rel="noopener ugc nofollow" target="_blank">自动驾驶到你目的地的特斯拉轿车</a>；很快，这些智能系统将会变得比现在更加集成，这种预期不无道理。通过工作、法律和正义的实施以及古老的战争习俗来发现意义的意义是巨大而全面的。在这个机械迷宫中寻找我们的道路需要新的思维形式，甚至可能需要一种模拟的有机思维，而不是在硅片之间焊接冷金属。</p></div></div>    
</body>
</html>