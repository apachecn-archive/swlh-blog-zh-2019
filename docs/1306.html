<html>
<head>
<title>Predicting categories of dev.to posts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测开发到职位的类别</h1>
<blockquote>原文：<a href="https://medium.com/swlh/predicting-categories-of-dev-to-posts-a681b3996cbf?source=collection_archive---------29-----------------------#2019-02-27">https://medium.com/swlh/predicting-categories-of-dev-to-posts-a681b3996cbf?source=collection_archive---------29-----------------------#2019-02-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/dfb6e86d5667e251b8ab6c068885ba67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5k89ZLg2UNwgqNJAmecjA.png"/></div></div></figure><p id="c739" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是我为自己选择的完整小型端到端数据科学项目的简短描述。我一直想玩文本数据，所以我选择创建自己的语料库。我稍后将使用它在其上应用一些机器学习。看看我如何预测一些博客文章的类别。</p><h1 id="529f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">目标</h1><p id="39bb" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">最近我学习了机器学习(ML)。有很多可能的应用领域:分析视频、图像、语音和文本。最后一个似乎最吸引我。在线内容每天都在增长。我们要读的东西太多了。自然语言处理(NLP)是数据科学对这个问题的回应。我这个小项目的内容来自一个很棒的开发者社区博客:<strong class="is kr"> dev.to </strong>。为了显示基本的ML，我将根据<em class="ks"> dev.to </em> post内容猜测标签。因此，我将运行监督学习。简而言之:我正在粘贴一个帖子的内容，它应该会告诉我这是关于“java”还是“python”。我作品的效果是一个web app，在这里随意摆弄<a class="ae kt" href="http://guess.lukaszkuczynski.usermd.net/" rel="noopener ugc nofollow" target="_blank">。为了简单起见，我只使用了4个主要类别。看看这个生活演示GIF:</a></p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/d1b067eb6c341451116a9589109bf27d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CzbpJR2vWpTiiOYL.gif"/></div></div></figure><h1 id="895d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">文集</h1><p id="6ac8" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">什么是<em class="ks">文集</em>？在NLP世界中，它是一组文档。我们稍后将分析这些文档。做任何一个ML项目，你都必须从一些要分析的东西开始。用一些数据。在自然语言处理中，你必须得到一些文本。从一些互联网门户网站上抓取它们并不是强制性的。你可以从内置语料库开始，因为它们是这里描述的<code class="du kz la lb lc b">nltk</code>库<a class="ae kt" href="https://www.nltk.org/book/ch02.html" rel="noopener ugc nofollow" target="_blank">的一部分</a>。在我的例子中，我想使用<code class="du kz la lb lc b">dev.to</code>数据，所以我将使用他们公开的API。我将创建自己的语料库。数据采集的过程是我的GitHub项目的一部分。用Python做这件事太简单了，我可以使用很棒的库，比如<code class="du kz la lb lc b">BeautifulSoap</code>和<code class="du kz la lb lc b">requests</code>。</p><h1 id="e409" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">弓</h1><p id="d18b" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated"><em class="ks"> BoW </em>首字母缩写代表<em class="ks">单词包</em>。这是一个简单的<em class="ks">矢量化</em>文本的方法。它的名字来源于这样一个想法:有一个袋子可以放所有的单词。我们不关心它们是如何排序的。我们只需要将我们的文本矢量化。这是在对文本应用任何ML算法之前的先决条件。那么这个向量对于一个简单的句子来说是什么样的呢？把<code class="du kz la lb lc b">CountVectorizer</code>作为Scikit学习库的一部分，让我们看看它是如何把文本转换成矢量的。</p><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="ld le l"/></div></figure><p id="f883" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果将是:</p><pre class="kv kw kx ky fd lf lc lg lh aw li bi"><span id="4486" class="lj jp hi lc b fi lk ll l lm ln">vocabulary is: [('do', 0), ('football', 1), ('how', 2), ('is', 3), ('like', 4), ('nice', 5), ('playing', 6), ('the', 7), ('violin', 8), ('you', 9)] <br/>matrix resulted is: [[0 0 0 0 1 0 1 1 1 0] [0 1 0 1 0 1 1 0 0 0] [1 1 1 0 1 0 1 0 0 1]]</span></pre><p id="28cc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们看看当我们把它想象成热图时是什么样子:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/17500c8aedaeb6d53758857534f8881b.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/0*10KbBB3YoUH9wAVm.png"/></div></figure><p id="09c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于我们将很快生产一个模型，我们希望它质量好。我们将执行一个<em class="ks"> Tf-Idf </em>(术语频率—逆文档频率)转换。这意味着我们要考虑这个词在文档中出现的频率(TF)和在其他文档中出现的频率(IDF)。在<code class="du kz la lb lc b">sklearn</code>中应用这种变换会产生一个与我们之前看到的略有不同的矩阵:</p><pre class="kv kw kx ky fd lf lc lg lh aw li bi"><span id="68cf" class="lj jp hi lc b fi lk ll l lm ln">vocabulary is: [('do', 0), ('football', 1), ('how', 2), ('is', 3), ('like', 4), ('nice', 5), ('playing', 6), ('the', 7), ('violin', 8), ('you', 9)] <br/>TfIdf matrix resulted is: [[0. 0. 0. 0. 0.44451431 0. 0.34520502 0.5844829 0.5844829 0. ] [0. 0.44451431 0. 0.5844829 0. 0.5844829 0.34520502 0. 0. 0. ] [0.4711101 0.35829137 0.4711101 0. 0.35829137 0. 0.27824521 0. 0. 0.4711101 ]]</span></pre><p id="2ece" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">和视觉化</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/f64fbc7de7e56c4cb37e40aac4324349.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/0*E_eRf7OD58z3C_3q.png"/></div></figure><p id="e8d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出矩阵现在有点不同了。这是因为我们关心术语在整个数据集中出现的频率。在我们这里，<em class="ks"> TfIdf </em>推崇稀有的如<em class="ks">小提琴</em>，贬低流行的如<em class="ks">演奏</em>。</p><h1 id="3723" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">机器学习</h1><p id="08ab" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">准备好向量后，我们可以在此基础上应用数学。在监督学习中，我们必须找到一个将输入向量X与标签y相匹配的函数。有了我们处理的数据的结构和种类，就需要应用正确的算法，而不仅仅是随机算法。如果你正面临这个问题，找到这个<code class="du kz la lb lc b"><a class="ae kt" href="http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" rel="noopener ugc nofollow" target="_blank">sklearn</a></code> <a class="ae kt" href="http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" rel="noopener ugc nofollow" target="_blank">备忘单</a>。在我的例子中，我正在对文本数据进行分类。我发现许多有经验的数据科学家倾向于使用朴素贝叶斯。经过几次尝试，我发现它也很有用。你可以在这里查看我的笔记本。记住，对于文本数据，我们使用多项式而不是高斯算法。这是模型训练过程中的一个片段。</p><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="ld le l"/></div></figure><p id="809b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请在我的报告中找到<a class="ae kt" href="https://github.com/lukaszkuczynski/guess" rel="noopener ugc nofollow" target="_blank">完整的代码库。</a></p><h1 id="7924" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">部署</h1><p id="fed3" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">一旦你的模型准备好了，就可以和别人分享了！用Azure或者AWS都可以。他们通常有现成的Docker容器，你只需要把你的模型放在里面，他们神奇地把它公开为一个REST服务。然而，当我第一次展示一些模型时，我希望一切都在掌控之中。这就是为什么我决定自己在web应用程序中构建我的模型。这就像将构建块序列化为文件，然后将这些文件上传到服务器一样简单。你可以去那里查看<a class="ae kt" href="http://guess.lukaszkuczynski.usermd.net/" rel="noopener ugc nofollow" target="_blank">我的app部署</a>。</p><h1 id="cbbf" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">经验教训</h1><p id="fe95" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">我认为这个项目并不完美。我测量了模型的准确性，它在80%左右。为了获得更好的结果，我们可以:</p><ul class=""><li id="5925" class="lp lq hi is b it iu ix iy jb lr jf ls jj lt jn lu lv lw lx bi translated">使用另一种算法，即集成算法，或调整现有算法</li><li id="68fa" class="lp lq hi is b it ly ix lz jb ma jf mb jj mc jn lu lv lw lx bi translated">拥有比数百个条目更多的数据(更多的数据总是意味着:更好)</li><li id="7966" class="lp lq hi is b it ly ix lz jb ma jf mb jj mc jn lu lv lw lx bi translated">更好地清理数据</li></ul><p id="e1a1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我很高兴看到用<code class="du kz la lb lc b">sklearn</code>处理数据是多么美好的体验。Python提供了必备的ML工具带。我也尝到了ML问题的全栈。我收集、分析、拟合模型，并最终部署它。</p></div><div class="ab cl md me gp mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="hb hc hd he hf"><p id="ce5b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="ks">原载于2019年2月18日</em><a class="ae kt" href="https://lukaszkuczynski.github.io/BoW_devto/" rel="noopener ugc nofollow" target="_blank"><em class="ks">lukaszkuczynski . github . io</em></a><em class="ks">。</em></p><figure class="kv kw kx ky fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es mk"><img src="../Images/308a8d84fb9b2fab43d66c117fcc4bb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqDjlKFwScoQYQ62DWEdig.png"/></div></a></figure><h2 id="c148" class="lj jp hi bd jq ml mm mn ju mo mp mq jy jb mr ms kc jf mt mu kg jj mv mw kk mx bi translated">这篇文章发表在<a class="ae kt" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是Medium最大的创业刊物，拥有+429，678读者。</h2><h2 id="869c" class="lj jp hi bd jq ml mm mn ju mo mp mq jy jb mr ms kc jf mt mu kg jj mv mw kk mx bi translated">在此订阅接收<a class="ae kt" href="https://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条新闻</a>。</h2><figure class="kv kw kx ky fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es mk"><img src="../Images/b0164736ea17a63403e660de5dedf91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouK9XR4xuNWtCes-TIUNAw.png"/></div></a></figure></div></div>    
</body>
</html>