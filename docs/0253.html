<html>
<head>
<title>On Decision Trees and Entropy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树与熵</h1>
<blockquote>原文：<a href="https://medium.com/swlh/on-decision-trees-and-entropy-7e6f26a4b014#2019-01-14">https://medium.com/swlh/on-decision-trees-and-entropy-7e6f26a4b014#2019-01-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0eae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树算法和熵函数的研究</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/8d0783feb5b4dd7d408aa06decffad60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W-9W_OZ9BoZY-9-BG8a8Yg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jt" href="https://unsplash.com/photos/UewgGfZgYj0?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Johannes Plenio</a> on <a class="ae jt" href="https://unsplash.com/search/photos/tree?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c0d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<strong class="ih ju">预测分析</strong>领域，决策树是可以应用于回归&amp;分类任务的算法之一</p><p id="fc92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树背后的思想是根据数据集中的要素在该点对响应变量的贡献，递归构建一个倒置的树状结构。在每次迭代中，将以这样的方式选择特征，使得结果模型最小化成本函数。</p><p id="60f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该结构从顶部的根节点开始，然后分支并连接到其他节点，最终到达树的终端节点或叶子。树中的每个节点代表一个特征；每个链接或分支代表一个决策，每个叶子代表一个结果(响应变量的类别或连续值)</p><h2 id="7dcc" class="jv jw hi bd jx jy jz ka kb kc kd ke kf iq kg kh ki iu kj kk kl iy km kn ko kp bi translated">利弊</h2><p id="7cd7" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">决策树背后的<strong class="ih ju">简单性</strong>是通过确定任何给定点的最重要特征来创建模型的方式。因为它<strong class="ih ju">没有假设</strong>变量之间是线性的或任何关系，它不仅限于线性或其他相关变量——它可以应用于任何数据集。此外，与许多其他算法不同，在应用决策树之前不需要大量的数据操作</p><p id="52dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它有时被称为<strong class="ih ju">贪婪</strong>算法，因为它在每一点都试图最大限度地最小化成本函数。这种过度的最小化成本函数的尝试会导致<strong class="ih ju">过度拟合</strong>训练数据，从而导致在测试数据上进行预测时的高方差。修剪或套袋等技术经常被用来解决这个问题</p><h2 id="bf7e" class="jv jw hi bd jx jy jz ka kb kc kd ke kf iq kg kh ki iu kj kk kl iy km kn ko kp bi translated">决策树的类型</h2><p id="4c20" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">根据所使用的成本最小化技术，决策树可以有许多分类，其中重要的一对是:</p><ul class=""><li id="afc6" class="kv kw hi ih b ii ij im in iq kx iu ky iy kz jc la lb lc ld bi translated">CART(分类和回归树)—使用基尼不纯度度量来计算每次迭代的信息增益</li><li id="839f" class="kv kw hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated">ID3(迭代二分法3) —使用熵函数来计算信息增益度量</li></ul><p id="84df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们将研究ID3决策树的熵函数&amp;设计一个算法来计算任何迭代的熵</p><h1 id="2c9b" class="lj jw hi bd jx lk ll lm kb ln lo lp kf lq lr ls ki lt lu lv kl lw lx ly ko lz bi translated">熵和信息增益</h1><p id="902a" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated"><strong class="ih ju"><strong class="ih ju">的熵</strong>每个特征</strong>的每个唯一值计算如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/7996651d90ddabe49e044195d8c481b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*BwK5kg3FZ0jwAg3J71irlw.png"/></div></figure><p id="8f33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">特征的<strong class="ih ju">信息增益</strong>计算如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/1b619d894b21f70bfe65ff09cc05fa82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*LDCO5vAqEc3jSQTdq6zgkA.png"/></div></figure><p id="b8f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中，E(T)是响应变量的熵</p><h2 id="b7de" class="jv jw hi bd jx jy jz ka kb kc kd ke kf iq kg kh ki iu kj kk kl iy km kn ko kp bi translated">履行</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/cd33cc62c9fa56123f97682a30261563.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*3TXniZQPbYgFDr04ZwpUfA.png"/></div></figure><p id="9aa2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用UCI数据仓库中的气球数据集。它代表实验的不同条件——根据4个预测特征确定“膨胀”的响应变量:颜色、大小、行为和年龄</p><pre class="je jf jg jh fd md me mf mg aw mh bi"><span id="1fec" class="jv jw hi me b fi mi mj l mk ml"># data = Balloons dataset<br/># N = Number of columns<br/># target = response variable<br/># en = Entropy of target variable<br/># cats = dictionary of counts of unique values for response variable<br/># vals = dictionary of counts of unique values for current feature</span><span id="f672" class="jv jw hi me b fi mm mj l mk ml">for i in range(0,N-1):<br/>    x=data.columns[i]<br/>    ig=0<br/>    for k, v in vals.items():<br/>        ent=0<br/>        <br/>        for k1 in cats.keys():<br/>            n=data.loc[(data[target]==k1) &amp; (data[x]==k), x].count()<br/>            prob = -(n/v) * np.log(n/v) <strong class="me ju">#Calculating Probability</strong><br/>            ent= ent + prob             <strong class="me ju">#Calculating Entropy</strong><br/>        info = info + ((v/total)*ent)   <strong class="me ju">#Calculating Information</strong><br/>        gain = en - ig                <strong class="me ju"># Calculating Information Gain</strong></span></pre><h2 id="3c62" class="jv jw hi bd jx jy jz ka kb kc kd ke kf iq kg kh ki iu kj kk kl iy km kn ko kp bi translated">在第一次迭代之后</h2><p id="8deb" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">让我们看看如何使用上面的函数计算第一次迭代的熵和信息增益</p><ol class=""><li id="c713" class="kv kw hi ih b ii ij im in iq kx iu ky iy kz jc mn lb lc ld bi translated">计算熵和信息增益w . r . t .<br/>列"颜色":<br/>'黄色':32，'紫色':28 <br/>"颜色"黄色带"膨胀"真-19<br/>"颜色"黄色带"膨胀"假-13<br/>"颜色"紫色带"膨胀"真-12<br/>"颜色"紫色带"膨胀"假-16<br/>E(黄色)=(-19/32)* log(19/32)+(-13/32)* log</li><li id="0d6e" class="kv kw hi ih b ii le im lf iq lg iu lh iy li jc mn lb lc ld bi translated">类似地，计算剩余列的熵和信息增益:<br/> IG(大小)= 0.0148 <br/> IG(行为)= 0.131 <br/> IG(年龄)= 0.130</li><li id="021c" class="kv kw hi ih b ii le im lf iq lg iu lh iy li jc mn lb lc ld bi translated">选择列“Act”作为根节点，因为它具有最高的信息增益</li></ol><h2 id="0342" class="jv jw hi bd jx jy jz ka kb kc kd ke kf iq kg kh ki iu kj kk kl iy km kn ko kp bi translated">后续步骤</h2><p id="c8da" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">然后，该算法将递归地执行以下步骤来构建决策树(超出了本文的范围):</p><ul class=""><li id="2d23" class="kv kw hi ih b ii ij im in iq kx iu ky iy kz jc la lb lc ld bi translated">具有最高信息增益的特征将被指定为该迭代的节点</li><li id="9a01" class="kv kw hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated">来自该节点的分支将由来自该节点的可能的每个唯一值(条件/决策)形成</li><li id="cc72" class="kv kw hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated">根据随后的特征和条件，分支将通向其他节点</li><li id="12c6" class="kv kw hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated">如果没有其他可能的特性或条件，将创建叶节点&amp;不会进行进一步的分支</li></ul><p id="d2d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这样，决策树将被递归地构建。然后，可以应用该模型来预测响应变量的值或类别</p><figure class="je jf jg jh fd ji er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es mo"><img src="../Images/308a8d84fb9b2fab43d66c117fcc4bb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqDjlKFwScoQYQ62DWEdig.png"/></div></a></figure><h2 id="c148" class="jv jw hi bd jx jy jz ka kb kc kd ke kf iq kg kh ki iu kj kk kl iy km kn ko kp bi translated">这篇文章发表在<a class="ae jt" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是Medium最大的创业刊物，拥有+411，714名读者。</h2><h2 id="869c" class="jv jw hi bd jx jy jz ka kb kc kd ke kf iq kg kh ki iu kj kk kl iy km kn ko kp bi translated">在这里订阅接收<a class="ae jt" href="http://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条新闻</a>。</h2><figure class="je jf jg jh fd ji er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es mo"><img src="../Images/b0164736ea17a63403e660de5dedf91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouK9XR4xuNWtCes-TIUNAw.png"/></div></a></figure></div></div>    
</body>
</html>