<html>
<head>
<title>Optimal CNN development: Use Data Augmentation, not explicit regularization (dropout, weight decay)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最佳CNN开发:使用数据扩充，而不是显式正则化(丢失、权重衰减)</h1>
<blockquote>原文：<a href="https://medium.com/swlh/optimal-cnn-development-use-data-augmentation-not-explicit-regularization-dropout-weight-decay-c46fb6b41c02#2019-06-15">https://medium.com/swlh/optimal-cnn-development-use-data-augmentation-not-explicit-regularization-dropout-weight-decay-c46fb6b41c02#2019-06-15</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><p id="c511" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hh bi translated">辍学，体重下降和数据增加都已成为每一个CNN开发人员的标准工具包的一部分。假设每个都以有希望的协同方式对产生最佳CNN做出贡献。然而，加西亚-柯尼希(<a class="ae jj" href="https://arxiv.org/abs/1806.03852v4" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1806.03852v4</a>)最近的研究探索了这一假设，并发现一个更好的开发方法是完全依靠数据增强来产生自我调整的CNN，并放弃使用辍学和…</p></div></div>    
</body>
</html>