<html>
<head>
<title>How to do mixup training from image files in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从Keras中的图像文件进行混音训练</h1>
<blockquote>原文：<a href="https://medium.com/swlh/how-to-do-mixup-training-from-image-files-in-keras-fe1e1c1e6da6#2019-01-13">https://medium.com/swlh/how-to-do-mixup-training-from-image-files-in-keras-fe1e1c1e6da6#2019-01-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9c87d51c25202818cad69eda78171b90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*npcTu74-i3TxjeUU.png"/></div></div></figure><p id="5172" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">之前，我们在Keras中介绍了<a class="ae jo" href="https://www.dlology.com/blog/bag-of-tricks-for-image-classification-with-convolutional-neural-networks-in-keras/" rel="noopener ugc nofollow" target="_blank">用卷积网络提高图像分类性能的一系列技巧</a>，这一次，我们将仔细看看最后一个叫做mixup的技巧。</p><h1 id="6404" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是mixup培训？</h1><p id="2359" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">论文<a class="ae jo" href="https://arxiv.org/pdf/1710.09412.pdf" rel="noopener ugc nofollow" target="_blank"> mixup:超越经验风险最小化</a>提供了传统图像放大技术如缩放和旋转的替代方案。通过对两个现有示例进行加权线性插值来形成新示例。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/c5ef78e16e1f5c7302ef1f43aadd7949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZqrucHTRyFsVqKw0.png"/></div></div></figure><p id="36fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">(Xi；yi)和(XJ；yj)是从我们的训练数据中随机抽取的两个例子，λ∈[0；1]，实际中λ是从β分布中随机抽样的，即β(α；α).</p><p id="4c62" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">α ∈ [0.1;0.4]导致性能提高，较小的α产生较少的混合效应，而对于较大的α，混合导致拟合不足。</p><p id="ab2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如您在下图中看到的，给定一个小的α = 0.2，beta分布采样更多更接近0和1的值，使得混合结果更接近两个示例中的任何一个。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es kx"><img src="../Images/47834618cd0290cd6ae93ba6af35aff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/0*1CYDk5Z_lqAi9KCD.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Beta distribution (α = 0.2)</figcaption></figure><h1 id="10b8" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">混搭训练有什么好处？</h1><p id="8a3b" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">虽然像Keras <a class="ae jo" href="https://keras.io/preprocessing/image/#imagedatagenerator-class" rel="noopener ugc nofollow" target="_blank"> ImageDataGenerator </a>类中提供的那些传统的数据扩充一直导致改进的泛化，但是该过程依赖于数据集，因此需要使用专家知识。</p><p id="41e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，数据扩充没有对不同类的例子之间的关系进行建模。</p><p id="fafa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另一方面，</p><ul class=""><li id="aa67" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated">Mixup是一个数据不可知的数据扩充例程。</li><li id="0be7" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">它使决策边界从一个类线性过渡到另一个类，提供了更平滑的不确定性估计。</li><li id="61c4" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">它减少了损坏标签的记忆，</li><li id="5933" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">它增加了对抗样本的鲁棒性，稳定了生成对抗网络的训练。</li></ul><h1 id="efbd" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">Keras中的Mixup图像数据生成器</h1><p id="3e3e" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">试图给mixup一个旋转？让我们实现一个图像数据生成器，它从文件中读取图像并开箱即用Keras <code class="du lq lr ls lt b">model.fit_generator()</code>工作。</p><figure class="kt ku kv kw fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="e3fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">mixup生成器的核心由一对迭代器组成，通过在<code class="du lq lr ls lt b">__next__</code>方法中执行的mixup，一次一批地从目录中随机采样图像。</p><p id="2cd7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，您可以创建用于拟合模型的训练和验证生成器，请注意，我们在验证生成器中没有使用mixup。</p><figure class="kt ku kv kw fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="d50b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以用Jupyter笔记本中的以下代码片段来可视化一批混乱的图像和标签。</p><figure class="kt ku kv kw fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="6967" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下图说明了mixup的工作原理。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/0e0bbb031fb3a514ed470388f461aad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/0*yLCQYAtNAh28LQks.png"/></div></figure><h1 id="9ecd" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论和进一步的思考</h1><p id="8e72" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">您可能会认为一次混合两个以上的示例可能会导致更好的训练，相反，三个或更多示例与从beta分布的多元泛化中采样的权重的组合不会提供进一步的增益，但会增加混合的计算成本。此外，仅在具有相同标签的输入之间进行内插不会导致混合的性能增益。</p><p id="6767" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我的Github上查看完整的源代码。</p><div class="lx ly ez fb lz ma"><a href="https://github.com/Tony607/keras_mixup_generator" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab dw"><div class="mc ab md cl cj me"><h2 class="hj b fi z dy mf ea eb mg ed ef hh bi translated">Tony607/keras_mixup_generator</h2><div class="mh l"><h3 class="bd b fi z dy mf ea eb mg ed ef dx translated">如何从Keras-Tony 607/Keras _ mixup _ generator中的图像文件进行混音训练</h3></div><div class="mi l"><p class="bd b fp z dy mf ea eb mg ed ef dx translated">github.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo io ma"/></div></div></a></div><p id="9c7e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://twitter.com/intent/tweet?url=https%3A//www.dlology.com/blog/how-to-do-mixup-training-from-image-files-in-keras/&amp;text=How%20to%20do%20mixup%20training%20from%20image%20files%20in%20Keras" rel="noopener ugc nofollow" target="_blank">在推特上分享</a> <a class="ae jo" href="https://www.facebook.com/sharer/sharer.php?u=https://www.dlology.com/blog/how-to-do-mixup-training-from-image-files-in-keras/" rel="noopener ugc nofollow" target="_blank">在脸书分享</a></p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><p id="4c84" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mw">原载于</em><a class="ae jo" href="https://www.dlology.com/blog/how-to-do-mixup-training-from-image-files-in-keras/" rel="noopener ugc nofollow" target="_blank"><em class="mw">www.dlology.com</em></a><em class="mw">。</em></p><figure class="kt ku kv kw fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es mx"><img src="../Images/308a8d84fb9b2fab43d66c117fcc4bb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqDjlKFwScoQYQ62DWEdig.png"/></div></a></figure><h2 id="c148" class="my jq hi bd jr mz na nb jv nc nd ne jz jb nf ng kd jf nh ni kh jj nj nk kl nl bi translated">这篇文章发表在<a class="ae jo" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是Medium最大的创业刊物，拥有+409，714名读者。</h2><h2 id="869c" class="my jq hi bd jr mz na nb jv nc nd ne jz jb nf ng kd jf nh ni kh jj nj nk kl nl bi translated">在这里订阅接收<a class="ae jo" href="http://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条新闻</a>。</h2><figure class="kt ku kv kw fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es mx"><img src="../Images/b0164736ea17a63403e660de5dedf91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouK9XR4xuNWtCes-TIUNAw.png"/></div></a></figure></div></div>    
</body>
</html>