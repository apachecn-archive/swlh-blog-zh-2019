# 智能边缘的机器学习模型优化

> 原文：<https://medium.com/swlh/machine-learning-model-optimization-for-intelligent-edge-d0f400111002>

![](img/fe60b0b98e7200dd8c4c16bb4b041f96.png)

智能边缘是一组不断扩展的连接系统和设备，用于收集和分析数据，接近最终用户和/或数据。用户可以获得实时的洞察力和体验，这些都是由高度响应和情境感知的应用程序提供的。毫无疑问，智能边缘提供了以前仅限于内部或云数据中心的分析功能。

术语“智能边缘”或“边缘智能”有多种用法，但也许最好的理解方式是把它看作一个活动发生的地方。它是一个制造车间，一栋建筑，一个校园，一个城市，你的房子，一片农田，一个风力农场，一个发电厂，一个石油钻塔，一个运动场，一个战场，在你的车里，在天上，或者在海底。它无处不在，是物联网(IoT)中“物”的所在。

> 基于云的人工智能为企业和消费者提供了按需商业智能。但是，为了有效地提供智能，人工智能必须存在于边缘，以通过实时分析和可操作的见解让用户受益。

# 为什么贴近用户很重要？

数据分析从云到边缘，再到智能和智能边缘的演变，是由真实的消费者需求引导的，支持性用例证明了这种架构转变。

![](img/2a2c7c9f3a6c4f283c48de6a46fb3f55.png)

随着 5G 等技术的到来，互联设备的使用和智能传感器的应用将呈指数级增长。这不仅会产生巨大的数据量，同时还会引发对亚毫秒级(或更短时间)内可操作洞察的不断增长的需求，以保证控制(物联网)设备的实时操作交付。

> 思科互联网业务解决方案集团预测:“到 2020 年将有 500 亿台联网设备”。

围绕物联网构建的用例层出不穷；家庭中正在使用设备来管理安全、能源、供水和电器。工厂通过预测性维护来优化运营和成本。城市正在控制交通，并将物联网应用于公共安全。物流公司正在跟踪货物，进行车队管理和优化路线。餐馆正在确保冰箱和油炸锅中的食品安全，零售商正在部署智能数字标牌和实施先进的支付系统——这样的例子不胜枚举。

为了应对这一挑战，单靠“核心”或“中央”云无法以这个时代预期的规模和速度提供服务。相反，将需要边缘上的支持(以单独的云实例的形式)来满足响应时间需求并交付卓越的用户体验。

在这篇文章中，我阐述了 edge 的需求，主要集中在 AI/ML 设计策略上，edge 扮演着核心角色。所以让我们开始吧。

# 人工智能/人工智能——不仅仅是一项奇特的技术

![](img/6d63d1740437c54a7919db7cc1be5505.png)

人工智能(AI)和机器学习(ML)的增长速度不仅会出现在我们的服务器、智能手机、家用电器和商业软件中，还会出现在每辆汽车、每栋建筑和每台医疗设备中。我们将很快到达这样一个点，如果我们做任何事情都没有智能，我们就无法做生意或度过一天。我们已经可以看到增长模式的出现:智能云越来越突出；智能应用变得无处不在。预测性应用程序编程接口(API)已经在医疗保健和物流环境中涌现，更不用说我们在互联网上经历的大量个性化营销了。

好吧！让我们回到我们的话题；现在可能很明显，单靠中央云战略无法有效地支持严格的延迟和性能要求。随着物联网的爆炸式增长，某些关键功能的卸载，包括近在咫尺的*机器智能、*需要正确地转移到高性能和低延迟的云，也就是*边缘*。

## 支持人工智能的智能边缘

机器学习对各地组织的未来至关重要，但从智能预测中驱动商业价值需要将人工智能系统连接到业务流程，无论它们在哪里。例如，使用基于机器学习的缺陷检测的制造商需要低延迟的结果，而不需要将数据发送到工厂之外。这就需要有一个*智能边缘*。

> 通过在边缘创建智能，您可以减少延迟和安全风险，同时改善用户体验，从而使您的业务流程更加高效。

智能是围绕人工智能和机器学习建立的，它脱离了原始数据和用户上下文。通过预先训练的模型处理，这些原始数据被转换成可操作的信息，使用户能够采取实时行动。

虽然人工智能在本文中占据了中心位置，但重要的是要注意，除了其他分析和实时应用程序，如 RTOS(实时操作系统)、数据库、数据收集/聚合、API 引擎等，人工智能/ML 只是难题的一部分。

在深入研究细节之前，我们将看看通常构成互联*物联网/边缘/核心*系统的不同层。下图显示了典型智能(IoT)设备和边缘设置中所需元素的高级物理布局。

![](img/1969043c5e11f1a5262bae401f0d54ef.png)

Smart devices and Intelligent Edge layout.

## 为什么边缘智力很重要？

边缘智能对物联网(IoT)和分布式网络有着重要的影响。由于更接近终端用户或数据，它在响应时间、效率和安全性方面比核心云具有邻近优势。

使用智能边缘技术有助于最大限度地提高业务效率。不是将数据发送到数据中心或其他第三方，而是在生成数据的位置执行分析。这不仅意味着这种分析可以更快地执行，而且还降低了数据被拦截或破坏的可能性。

更令人感兴趣的是将边缘计算和机器学习(ML)相结合的应用，这些应用可以在从移动和联网家庭到安全、监控和汽车等行业带来新的体验和新的机会。

在这篇博客的后面部分，你会看到针对边缘计算云和物联网设备的机器学习模型培训的讨论。更具体地说，我将讨论正则化和优化技术，同时牢记有监督的*深度学习*。

在您的数据科学项目中实现这样的实践将会产生丰硕的成果。在训练和执行时间方面，您可以产生更高效的机器学习模型，并最大限度地减少存储需求。

# 连续机器学习系统

如果您发现数据分布与原始训练数据分布有很大差异，那么最好是持续监视传入的数据，并使用较新的数据重新训练您的模型。下图描述了这种架构方法。

![](img/33ecfb3866c91f07eebb980cb59b2ead.png)

Machine Learning process architecture targeted for edge supported by multiple layers.

它描绘了一个典型的机器学习过程，强调了三个不同的层次，**物联网**、**核心**和**边缘**云。让我们展开它。首先，在主过程之外，标记的(训练)数据与单个或多个资源分开保护。然后，这些数据被送入 ML 算法进行模型训练，这(出于实际原因)发生在后端核心中。由于(接近)无限的容量和处理能力可用性，核心已准备好承担模型训练的重任。一旦模型达到可接受的精确度，它就被部署在边缘上，以基于从设备本地收集的数据来提供数据洞察和实时推断。模型*训练*，随后是*修剪*(去除多余脂肪)和*验证*经过一个迭代循环，在投入生产之前生成一个最佳模型。

这创建了一个闭环系统，该系统包含了采取用户动作，然后将它们反馈到数据集中进行重新训练的方法。这需要新的功能或修改地面真相或两者兼而有之。对新版本进行再培训有助于提高准确性，并增加处理更大范围数据输入的能力。

在一个典型的多层、多段系统中，你应该注意子系统的特征。例如，与后端云数据中心相比，边缘计算层应该具有更少的存储和计算能力。高性能和高吞吐量是满足实时流量对低延迟和快速响应时间的要求所必需的。当涉及到重新培训时，需要在边缘和核心云之间仔细划分任务，以保持业务目标，同时在更好的准确性方面获得改进。

# 培训流程生命周期

尽管使用流行的科学库很容易创建和部署 ML 模型，但是需要特定的优化和修剪技术来产生功能性和生产性的模型。当涉及到边缘云和/或终端设备上的模型部署时，这种需求会进一步加剧。在这篇文章中，我选取了一个在边缘上运行的云感知应用程序(如虚拟网络功能)的示例，尽管如此，在物联网设备上培训和部署该模型也可以遵循类似的实践。

下图说明了利用*继续学习*方法的 ML 模型的生命周期，该方法涉及上述层，即**物联网**、**边缘**和**核心**云。

![](img/8cebe6b379fd0cfecfa3ce520554db81.png)

Feedback loop to improve AI capability base don new data samples.

重要的是，有这个概念的*反馈回路*和在线*模型训练/更新*阶段。预训练和优化在全面的中央云中进行，利用其几乎无限的能力和空间。通过用更多的实际现场数据改进模型容量，在运行时产生更好的功能模型。它可以在多个(边缘)设备上共享，方法是将这些设备用于多个任务，每个设备并行工作。

接下来，让我们更深入地了解监督 ML 模型优化技术的技术方面，这被许多行业领导者视为必修的模型工程练习。

# 动机和策略

与任何流程优化非常相似，ML 模型优化的目标是在资源受限环境下执行时实现高效的运行时性能。该过程包括通过应用优化实践和算法的组合来逐步实现可测量的改进。

> 很重要的一点是，要很好地掌握不同的优化技巧，这样你就可以辨别哪种技术和实践会产生想要的结果。

要定义特别适用于资源限制边缘情况的 ML 策略，下面的列表会很有用:

1.  根据对能耗和计算性能的估计，选择合适的芯片组
2.  一段时间内的存储要求
3.  延迟和吞吐量要求
4.  了解你的工作量
5.  了解你的交通模式
6.  了解您的数据增长
7.  了解内存/存储要求
8.  超参数知识和调整
9.  重新利用空间，减少存储过度使用/过度消耗
10.  训练和保存(核心)、传输(模型)和加载(边缘)
11.  人工智能服务的容器化——精心编排且易于管理
12.  可再生且安全的管道(例如使用 kubeflow)

![](img/90f96014822633ad505225a7733816f7.png)

## 利益

由于多种原因，Mmodel 优化是必要的，其中一些原因如下:

*   *所需资源更少*:将模型部署到处理、内存或功耗受限的边缘设备。比如移动和物联网(IoT)设备。
*   *效率*:减小模型尺寸有助于提高生产率，尤其是部署在边缘时。
*   *延迟:*没有到服务器的往返，坚持合规性
*   *隐私:*数据无需离开设备或边缘网关，因此安全性更高
*   *连接:*业务运营不需要互联网连接
*   *功耗:*矩阵乘法运算需要计算能力。更少的神经元意味着更少的功耗。

## 技术

这个想法是为了制造在速度、记忆和存储方面更有效的工程模型。在接下来的几个部分中，我将介绍一些在行业中广泛使用的技术，用于创建优化的深度学习模型。所以让我们开始吧！

## 1.修剪

*修剪 desc* 描述了一套修剪网络大小(通过节点而不是层)的技术，以提高计算性能，有时也提高分辨率性能。这些技术的要点是在训练期间通过识别那些如果从网络中移除不会显著影响网络性能(即，数据的分辨率)的节点来从网络中移除节点。

即使不使用正式的剪枝技术，你也可以通过训练后查看你的权重矩阵来大致了解哪些节点不重要；看起来权重非常接近于零-在修剪过程中，这些权重两端的节点通常会被删除。

> 修剪神经网络是一个可以追溯到 1990 年[(有颜乐存的最优脑残作品)](http://yann.lecun.com/exdb/publis/pdf/lecun-90b.pdf)及之前的老思想。

这个想法是，在网络的许多参数中，有些是冗余的，对输出没有太大贡献。

如果你可以根据神经元的贡献大小对网络中的神经元进行排序，那么你就可以从网络中移除排序较低的神经元，从而形成一个更小、更快的网络。

**修剪算法**

通过在训练期间对您的网络应用修剪算法，您可以接近最佳网络配置。

神经元的排名可以根据 *L1/L2* 的平均权重、它们的平均激活、某个验证集上神经元不为零的次数以及其他创造性的方法来完成。

修剪之后，准确度会下降(如果排名聪明，希望不会下降太多)，并且网络通常被训练得更多以恢复。

## 2.降维

在处理现实世界的问题时，我们经常会处理可能跨越数百万个数据点的高维数据。根据您的算法选择，像主成分分析和 RFE 技术可以证明是非常有用的减少数据维度，从而减少模型的空间需求。

虽然我在这里提到了它，但是，对于基于神经网络的学习算法，不推荐使用它。其他技术，例如上面描述的技术和接下来章节中的技术，更适合于优化深度学习模型。

## ***2。量化***

*量化*技术在训练期间应用时特别有效，并且可以通过减少用于模型权重和激活的比特数来提高推理速度。例如，使用 8 位定点表示代替浮点表示，可以加快模型推断的速度，降低功耗，并进一步将尺寸减小 4 倍。

随着讨论的深入，我们将会看到一些技巧和有用的提示。

1.  通过修剪和结构化修剪减少参数数量。实际上将神经网络参数值设置为零，从而创建稀疏神经网络(矩阵)。稀疏矩阵倾向于产生更好的压缩，导致整体模型尺寸减小。
2.  通过量化降低表示精度。量化深度神经网络使用的技术允许降低权重的精度表示，并可选地激活存储和计算。人们发现，当与量化相结合时，权重修剪产生复合效益。
3.  将原始模型拓扑更新为更有效的拓扑，减少参数或加快执行速度。比如张量分解法和蒸馏法。

## 4.正规化

数据科学专业人员面临的最常见问题之一是避免过度拟合。避免过度拟合可以单独提高模型的性能。L1 和 L2(权重衰减)是最常见的正则化类型。这些方法通过添加另一个称为正则化项的项来更新一般成本函数。具体地；

*成本函数=损失(比如说，二元交叉熵)+正则化项*

加权矩阵 W 合理地接近于零。因此，一个直觉是，对于许多隐藏单元来说，它将权重设置得如此接近于零，这基本上消除了这些隐藏单元的许多影响。

我们可以把它看作是归零，或者至少是减少许多隐藏单元的影响，这样你最终可能会感觉到一个更简单的网络。事实证明，实际发生的是，他们仍然会使用所有的隐藏单元，但每个单元的效果会小得多。

但是你最终得到了一个更简单的网络，就好像你有一个更小的网络，因此不容易过度拟合。

## 5.超参数调谐

通过调整超参数，可以设计高效的网络，这将在资源受限的情况下(如在物联网设备或 MEC 上)产生卓越的运行时性能。

一些用户最喜欢的是:

**神经网络深度** —具体而言，神经网络的深度和每个隐藏层的神经元数量增强了模型处理更复杂决策边界的能力。每层神经元数量和层数的选择构成了所谓的网络架构。当决定隐藏层的尺寸时，没有硬性的规则；相反，您的架构选择将基于从不同组合中获得的经验结果。通常，你会把*隐藏层的数量*作为一个可调的超参数，并在向前传递时使用。

**退出率** —退出是一种*对抗过度拟合*和提高神经网络泛化能力的技术。这是最有趣的正则化技术之一，也是深度学习领域最常用的技术。

![](img/871ec4370915a00fc3dfefd121693252.png)

> 通过随机丢弃(归零权重)一些神经元来减小层的大小几乎总是有效的。

退出也是对模型过度拟合的一种防御机制。在每次迭代中，它会随机选择一些节点，并删除它们以及它们所有的传入和传出连接。辍学率是一个超参数，它控制神经元/权重的归零，并由所有主要的 ML 库(如 Keras)支持。该值通常设置在 0.25-0.50 之间。

## 6.硬件加速

在其核心，神经网络是多维数组(矩阵或张量)，对数学运算，如加法和乘法进行操作。诸如 FPGA、TPU 或 GPU 之类的专用硬件快速操纵和改变存储器，以加速整个过程，例如模型训练及其执行。

Edge TPU 是谷歌专门打造的 ASIC，旨在边缘运行人工智能。它以较小的物理和功耗提供高性能，支持在边缘部署高精度人工智能。

其他解决方案，如 Xnor AI 的 AI2GO，提供预先构建的专用模型，可以在小型廉价设备上自动运行，包括 Raspberry Pi，无需连接到互联网或中央云。

## **7。轻量级框架**

2017 年 5 月，谷歌推出了用于移动边缘设备开发的 TensorFlow Lite。它旨在使在边缘执行机器学习变得容易，而不是将数据来回发送到服务器。TensorFlow Lite 适用于从微型微控制器到功能强大的移动电话的各种设备。

## 将所有这些放在一起——管道

最后，您可能希望将所有的预处理和数据操作作为模型创建的一部分插入/缝合在一起。对于有效的数据工程和模型训练，管道通常用于此类任务。

总的来说，这些数据管道构成了控制处理逻辑的工作流，并跨越了典型 ML 项目中的不同边界。

![](img/175f5f0c63a3c7707e754b087971a063.png)

Courtesy of Microsoft [Azure](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines) website.

有多个选项可用，比如 Kubeflow、AutoML、Azure ML Pipelines。

## 专用框架

像谷歌的 [*Learn2Compress*](https://ai.googleblog.com/2018/05/custom-on-device-ml-models.html) 这样的框架，通过结合几种压缩神经网络模型的最先进技术来概括学习。它将用户提供的大型预训练 TensorFlow 模型作为输入，执行训练和优化，并自动生成现成可用的设备上模型，这些模型尺寸更小、内存效率更高、能效更高、推断速度更快，精确度损失最小。

# 参考

[1]智能优势就在您的未来—[https://www . Cisco . com/c/en/us/solutions/enterprise-networks/intelligent-Edge . html](https://www.cisco.com/c/en/us/solutions/enterprise-networks/intelligent-edge.html)

[2]西部数据—[https://blog . Western Digital . com/machine-learning-edge-devices/](https://blog.westerndigital.com/machine-learning-edge-devices/)

[3] TensorFlow 修剪 API—[https://medium . com/tensor flow/tensor flow-model-optimization-toolkit-Pruning-API-42 CAC 9157 a6a](/tensorflow/tensorflow-model-optimization-toolkit-pruning-api-42cac9157a6a)

[4]tensor flow Lite—[https://www.tensorflow.org/lite/guide](https://www.tensorflow.org/lite/guide)

[5][https://ai . Google blog . com/2018/05/custom-on-device-ml-models . html](https://ai.googleblog.com/2018/05/custom-on-device-ml-models.html)

[6][https://heart beat . fritz . ai/how-to-fit-large-neural-networks-on-the-edge-EB 621 cdbb 33](https://cloud.google.com/edge-tpu/)

[7][https://www . einfochips . com/blog/ml-at-the-edge-will-help-unleash-the-true-potential-of-IOT/](https://www.einfochips.com/blog/ml-at-the-edge-will-help-unleash-the-true-potential-of-iot/)

[8][https://Jacob Gil . github . io/deep learning/pruning-deep-learning](https://jacobgil.github.io/deeplearning/pruning-deep-learning)

[9]https://cloud.google.com/edge-tpu/边缘的 TPU—