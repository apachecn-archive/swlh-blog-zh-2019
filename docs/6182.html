<html>
<head>
<title>What’s in a neural network recommender</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络推荐器里有什么</h1>
<blockquote>原文：<a href="https://medium.com/swlh/whats-in-a-neural-network-recommender-a6fb9fb8cb37?source=collection_archive---------66-----------------------#2019-06-18">https://medium.com/swlh/whats-in-a-neural-network-recommender-a6fb9fb8cb37?source=collection_archive---------66-----------------------#2019-06-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="de84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基于项目的协同过滤(IBCF)算法<a class="ae jd" href="https://pdfs.semanticscholar.org/0f06/d328f6deb44e5e67408e0c16a8c7356330d1.pdf" rel="noopener ugc nofollow" target="_blank">在2017年获得了</a>的“时间的考验”认可，比AlphaGo Master晚了一年，谷歌可以学习下围棋的神经网络<a class="ae jd" href="https://www.computer.org/csdl/magazine/ic/2017/03/mic2017030012/13rRUB6SpQq" rel="noopener ugc nofollow" target="_blank">赢了</a>最聪明的人类围棋选手之一Lee Sedol。</p><p id="7c75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在工作中，我总是喜欢选择简单的算法，而不是更复杂的算法——当两者的性能相似时——简单的算法运行和实现所需的时间更少，但现在无法抑制地发现一个基本的神经网络自动编码器如何执行建议，特别是在神经网络和深度学习的所有宣传中，以及从训练到生产都可以轻松实现神经网络模型的软件包(read: tensorflow)的可用性。</p><p id="c80f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看一个简单的自动编码器(一个输入和输出一样多的神经网络)如何与经典的IBCF算法竞争。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><p id="e1be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用<a class="ae jd" href="https://grouplens.org/datasets/movielens/100k/" rel="noopener ugc nofollow" target="_blank"> MovieLens 100K </a>数据集，并且我们将在<a class="ae jd" href="http://www.cs.carleton.edu/cs_comps/0607/recommend/recommender/collaborativefiltering.html" rel="noopener ugc nofollow" target="_blank">隐式模式</a>中使用它，这意味着推荐器将基于每个用户的已知电影评级来预测一个人还会观看哪些电影(或者，严格地说，评级)。</p><p id="adc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了使数据集对应于隐式表示，如果是任何评级，则评级被转换为1，否则转换为0。术语“交互”被进一步用来描述用户已经对给定电影进行评级的事实。</p><p id="4cd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据分为训练和测试，80%和20%。</p><p id="116f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过从每个用户的交互集合中隐藏一个交互，输出<em class="jl"> k </em>个最佳推荐，并在<em class="jl"> k </em> (HR@k) <em class="jl">，</em> HR = TP / P处评估平均<a class="ae jd" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank"> <em class="jl">命中率</em> </a> <em class="jl"> </em>(在我们的设置中，P总是1，因为每个用户只有1个隐藏的交互，而TP可以是1或0，这取决于隐藏的交互是否是推荐的集合【T2</p><p id="4a93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所选的性能指标根据隐藏的项目而变化，因此对每个模型执行10次性能评估，并报告平均HR@k。</p><p id="c5fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">几个辅助函数(<a class="ae jd" href="https://gist.github.com/dimalvovs/7b27b75159437ec2d1a6ab1008eb5e2e" rel="noopener ugc nofollow" target="_blank">此处可用</a>)用于格式化数据、评估性能和进行预测:</p><ul class=""><li id="f4c3" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated"><strong class="ih jv">makeRecommendlabTrainSets()</strong>将数据格式化为用户项二进制矩阵，将数据拆分为训练集和测试集；</li><li id="9b89" class="jm jn hi ih b ii jw im jx iq jy iu jz iy ka jc jr js jt ju bi translated"><strong class="ih jv">mask interaction()</strong>is<strong class="ih jv"/>用于删除一个用户交互，以便能够稍后用模型重建它，这对评估模型性能很有用；</li><li id="92fc" class="jm jn hi ih b ii jw im jx iq jy iu jz iy ka jc jr js jt ju bi translated"><strong class="ih jv"> assessGuess() </strong>将实际丢弃的交互与由模型——IBCF、NN和简单预测提出的交互列表进行比较<em class="jl"> k </em>最频繁出现的电影；</li><li id="22af" class="jm jn hi ih b ii jw im jx iq jy iu jz iy ka jc jr js jt ju bi translated"><strong class="ih jv"> netPredictOne() </strong>是一个包装器函数，使用NN模型进行一次预测，对本文来说有点多余，是我在另一个项目中使用的；</li></ul><p id="5d99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于经典算法，来自R包<a class="ae jd" href="https://cran.r-project.org/web/packages/recommenderlab/index.html" rel="noopener ugc nofollow" target="_blank">推荐器lab </a>的项目-项目协作过滤算法用于所有默认设置，对于NN模型，它是一个简单的自动编码器，具有一个大小为输入大小1/3的隐藏层，用<a class="ae jd" href="https://cran.r-project.org/web/packages/keras/index.html" rel="noopener ugc nofollow" target="_blank"> keras </a>训练。为了将这两种模型与最简单的替代方案进行比较，我们还评估了一种最常见的相互作用模型，即MFM模型。所有的模型都预测了top <em class="jl"> k </em> =10个交互。</p><p id="6d9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可重复结果的完整代码可在获得<a class="ae jd" href="https://gist.github.com/dimalvovs/d884ace8318b9a4e674d1ecc75b5ff6d" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><p id="f040" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神经网络模型是最准确的一个，其HR@10为0.22，是IBCF模型(0.11)的两倍，几乎是最频繁相互作用模型(0.08)的3倍。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es kb"><img src="../Images/552d6c6fff0bb23fb486031c7830fe50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_MP4c8oaM9giH6PwJhib3w.png"/></div></div></figure><p id="29ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IBCF模型推荐精度对应于由<a class="ae jd" href="https://lyst.github.io/lightfm/docs/examples/movielens_implicit.html" rel="noopener ugc nofollow" target="_blank"> others </a>在相同数据集上获得的精度。正如所料，MF模型的准确性最低。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><p id="4f95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们比较神经网络和IBCF模型的隐式推荐的小实验中，神经网络表现得令人惊讶地好，比经典的IBCF模型好得多。然而，根本没有发生数据清理，也没有为IBCF模型尝试各种距离度量。此外，除了隐藏层的大小或输入大小的1/3之外，没有进行超参数调整，这在以前的经验中效果最好。</p><p id="fce5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当训练NN模型时，测试集和验证集是相等的，因为数据集非常小，但是在训练期间不使用测试集并且当训练误差没有改善时停止产生相同的结果。</p><p id="581f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，我对使用神经网络来学习机器生成的数据(图像/视频/声音)以外的任何东西持怀疑态度，但考虑到向神经网络提供辅助输入数据是多么容易，并且可能进一步提高推荐质量，神经网络似乎有机会成为更好的推荐器。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><ul class=""><li id="86f6" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated"><a class="ae jd" rel="noopener" href="/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d"> Autoencoder推荐文章</a>，可惜没有性能评估</li><li id="4f1a" class="jm jn hi ih b ii jw im jx iq jy iu jz iy ka jc jr js jt ju bi translated"><a class="ae jd" href="http://www.cse.scu.edu/~yfang/ACDA.pdf" rel="noopener ugc nofollow" target="_blank">一篇关于去噪自动编码器的论文</a>征求建议，由于某种原因结果大相径庭</li><li id="e0d6" class="jm jn hi ih b ii jw im jx iq jy iu jz iy ka jc jr js jt ju bi translated"><a class="ae jd" href="https://lyst.github.io/lightfm/docs/index.html" rel="noopener ugc nofollow" target="_blank">light FM python模块中IBCF方法</a>的类似结果</li><li id="5012" class="jm jn hi ih b ii jw im jx iq jy iu jz iy ka jc jr js jt ju bi translated">另一篇<a class="ae jd" href="https://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/" rel="noopener ugc nofollow" target="_blank"> autoencoder文章</a>是我用来获得灵感的，写得非常好</li><li id="5c05" class="jm jn hi ih b ii jw im jx iq jy iu jz iy ka jc jr js jt ju bi translated"><a class="ae jd" href="https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models" rel="noopener ugc nofollow" target="_blank">多个输入和输出网络</a></li></ul></div></div>    
</body>
</html>