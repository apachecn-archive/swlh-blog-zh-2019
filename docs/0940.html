<html>
<head>
<title>How to train an object detection model easy for free</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何免费训练一个简单的物体检测模型</h1>
<blockquote>原文：<a href="https://medium.com/swlh/how-to-train-an-object-detection-model-easy-for-free-f388ff3663e#2019-02-12">https://medium.com/swlh/how-to-train-an-object-detection-model-easy-for-free-f388ff3663e#2019-02-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ec911820f04137da61184426eb55722c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cHNVKisdYdejpDvf.png"/></div></div></figure><p id="5974" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本教程中，您将学习如何使用TensorFlow对象检测API和Google Colab的免费GPU轻松训练自定义对象检测模型。</p><p id="1a81" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">包括注释图像和源代码来完成本教程。</p><h2 id="4697" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">TL:DR；打开<a class="ae kj" href="https://colab.research.google.com/github/Tony607/object_detection_demo/blob/master/tensorflow_object_detection_training_colab.ipynb" rel="noopener ugc nofollow" target="_blank">Colab笔记本</a>开始探索。</h2><p id="278d" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">否则，让我们从创建带注释的数据集开始。</p><h1 id="5afd" class="kp jp hi bd jq kq kr ks ju kt ku kv jy kw kx ky kb kz la lb ke lc ld le kh lf bi translated">步骤1:注释一些图像</h1><p id="5471" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">在此步骤中，您将找到/拍摄图片并注释对象的边界框。只有当你想用你的图片而不是用<a class="ae kj" href="https://github.com/Tony607/object_detection_demo" rel="noopener ugc nofollow" target="_blank"> <strong class="is lg">我的库</strong> </a>自带的图片时才有必要。</p><p id="f692" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你的对象是简单的，比如我例子中的坚果和水果，20张图片就足够了，每张图片包含多个对象。</p><p id="a5bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我的例子中，我用我的iPhone来拍摄这些照片，每张都有4032 x 3024的分辨率，如果我们用它作为模型的直接输入，它会淹没模型。相反，将这些照片调整到统一的尺寸<code class="du lh li lj lk b">(800, 600)</code>可以使训练和推断更快。</p><p id="ea16" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以使用存储库中的<a class="ae kj" href="https://github.com/Tony607/object_detection_demo/blob/master/resize_images.py" rel="noopener ugc nofollow" target="_blank"> resize_images.py </a>脚本来调整图像的大小。</p><p id="5752" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，保存你的照片，最好是用<code class="du lh li lj lk b">jpg</code>扩展到<code class="du lh li lj lk b">./data/raw</code>目录。然后跑，</p><pre class="ll lm ln lo fd lp lk lq lr aw ls bi"><span id="ecfb" class="jo jp hi lk b fi lt lu l lv lw">python resize_images.py --raw-dir ./data/raw --save-dir ./data/images --ext jpg --target-size "(800, 600)"</span></pre><p id="7845" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">调整后的图像将位于<code class="du lh li lj lk b">./data/images/</code></p><p id="a606" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将这些文件分成两个目录，<code class="du lh li lj lk b">./data/images/train</code>和<code class="du lh li lj lk b">./data/images/test</code>。该模型将只使用“<strong class="is lg"> train </strong>目录中的图像进行训练，而“<strong class="is lg"> test </strong>目录中的图像作为评估模型性能的附加数据。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/add661071ded58df0ab17a0be1060108.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*P0RnBcWg3cF0fBjT.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx">labelImg</figcaption></figure><p id="051a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用<a class="ae kj" href="https://tzutalin.github.io/labelImg/" rel="noopener ugc nofollow" target="_blank"> <strong class="is lg"> labelImg </strong> </a>给调整大小的图像添加注释，这个注释工具支持Windows和Linux，它会在<code class="du lh li lj lk b">./data/images/train</code>和<code class="du lh li lj lk b">./data/images/test</code>目录下生成<code class="du lh li lj lk b">xml</code>文件。</p><p id="32c6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mc">提示:使用快捷键(</em> <code class="du lh li lj lk b"><em class="mc">w</em></code> <em class="mc">:绘制框、</em> <code class="du lh li lj lk b"><em class="mc">d</em></code> <em class="mc">:下一个文件、</em> <code class="du lh li lj lk b"><em class="mc">a</em></code> <em class="mc">:上一个文件等。)加速标注。</em></p><h1 id="8b16" class="kp jp hi bd jq kq kr ks ju kt ku kv jy kw kx ky kb kz la lb ke lc ld le kh lf bi translated">第二步:准备<code class="du lh li lj lk b">tfrecord</code>文件(源包含在Colab笔记本中)</h1><p id="d5b4" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">在运行这个步骤之后，您将拥有两个文件<code class="du lh li lj lk b">train.record</code>和<code class="du lh li lj lk b">test.record</code>，它们都是二进制文件，每一个都包含相应训练/测试集的编码jpg和边界框注释信息。与分别存储每个图像和注释相比，tfrecord文件格式在训练阶段更易于使用，加载速度也更快。</p><p id="6c28" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这样做有两个步骤:</p><ul class=""><li id="6804" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated">为每组(训练/测试)将单独的<code class="du lh li lj lk b">*.xml</code>文件转换为统一的<code class="du lh li lj lk b">*.csv</code>文件。</li><li id="ea1f" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated">将每组(训练/测试)的注释<code class="du lh li lj lk b">*.csv</code>和图像文件转换为<code class="du lh li lj lk b">*.record</code>文件(TFRecord格式)。</li></ul><p id="1d78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用以下脚本生成<code class="du lh li lj lk b">tfrecord</code>文件和<code class="du lh li lj lk b">label_map.pbtxt</code>文件，它们将每个对象类名映射到一个整数。</p><figure class="ll lm ln lo fd ij"><div class="bz dy l di"><div class="mr ms l"/></div></figure><h1 id="beb0" class="kp jp hi bd jq kq kr ks ju kt ku kv jy kw kx ky kb kz la lb ke lc ld le kh lf bi translated">步骤3:配置培训管道</h1><p id="f0c9" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">我们不是从零开始训练模型，而是从一个预先训练好的模型进行迁移学习，以检测日常物体。</p><p id="39c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与从头开始训练相比，迁移学习需要更少的训练数据。</p><p id="cd6b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是请记住，迁移学习技术假设您的训练数据与用于训练基本模型的数据有些相似。在我们的例子中，使用普通对象的<a class="ae kj" href="http://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> coco数据集</a>训练基本模型，我们希望训练模型检测的3个目标对象是水果和坚果，即“枣”、“无花果”和“榛子”。它们类似于coco数据集中的那些。另一方面，如果您的目标对象是CT图像中的肺结节，迁移学习可能不会很好地工作，因为它们与coco数据集公共对象相比完全不同，在这种情况下，您可能需要更多的注释，并从头开始训练模型。</p><p id="52c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了进行迁移学习培训，我们首先将下载预培训的模型重量/检查点，然后配置相应的pipeline配置文件，以告知培训师以下信息。</p><ul class=""><li id="5256" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated">预训练模型检查点路径(微调检查点)，</li><li id="6d94" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated">这两个tfrecord文件的路径，</li><li id="66d7" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated"><strong class="is lg"> label_map.pbtxt </strong>文件的路径(label_map_path)，</li><li id="14b8" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated">训练批次大小(batch_size)</li><li id="d451" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated">训练步数(num_steps)</li><li id="6113" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated">唯一对象的类别数(num_classes)</li></ul><h1 id="f8fb" class="kp jp hi bd jq kq kr ks ju kt ku kv jy kw kx ky kb kz la lb ke lc ld le kh lf bi translated">第四步:训练模型</h1><p id="61ad" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">在那之后，我们可以开始训练，这里的<strong class="is lg"> model_dir </strong>是存储我们的输出模型的新目录的路径。</p><figure class="ll lm ln lo fd ij"><div class="bz dy l di"><div class="mr ms l"/></div></figure><p id="1324" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在colab笔记本中，TensorBoard还配置为帮助您可视化训练进度和结果。这里有两张TensorBoard的截图，显示了对测试图像的预测和对损失值的监控。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/ca13707dcf055295fba455d15b3b15b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Xp4k41JZBRW9sYr3.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx">TensorBoard Images</figcaption></figure><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/cf2ec45370e12455b1cd576b356b381e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Oiv1zRWEi350f819.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx">TensorBoard Scalars</figcaption></figure><h1 id="97c0" class="kp jp hi bd jq kq kr ks ju kt ku kv jy kw kx ky kb kz la lb ke lc ld le kh lf bi translated">步骤5:导出并下载一个训练好的模型</h1><p id="ce72" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">一旦您的训练工作完成，您需要提取新训练的模型作为推理图，它将在以后用于执行对象检测。转换可以按如下方式进行:</p><figure class="ll lm ln lo fd ij"><div class="bz dy l di"><div class="mr ms l"/></div></figure><p id="c78f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以在路径<strong class="is lg">fine _ tuned _ model/frozen _ inference _ graph . Pb</strong>找到模型冻结图文件。可以通过Google Drive下载，也可以像colab笔记本上显示的那样直接下载。</p><p id="5e74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">笔记本的最后一部分告诉你如何加载<strong class="is lg">。pb </strong>文件、<strong class="is lg"> label_map.pbtxt </strong>文件，并对一些测试图像进行预测。下面是一个检测输出示例。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/3313d3bea3ff2027284974ae81925100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/0*ETy47hmNSMZdHXCJ.png"/></div></figure><h1 id="81d4" class="kp jp hi bd jq kq kr ks ju kt ku kv jy kw kx ky kb kz la lb ke lc ld le kh lf bi translated">结论和进一步的思考</h1><p id="6e07" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">训练对象检测模型可能是资源密集且耗时的。本教程向您展示了它可以像注释20幅图像一样简单，并在Google Colab上运行一个Jupyter笔记本。未来，我们将研究在不同的硬件中部署经过训练的模型，并对它们的性能进行基准测试。举几个部署选项的例子，</p><ul class=""><li id="7b67" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated">英特尔CPU/GPU采用OpenVINO工具套件加速，FP32和FP16量化模型。</li><li id="22b5" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated">Movidius神经计算棒与OpenVINO工具包。</li><li id="0f88" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated">Nvidia GPU与Cuda工具包。</li><li id="7cd7" class="md me hi is b it mm ix mn jb mo jf mp jj mq jn mi mj mk ml bi translated">具有NPU的SOC，如Rockchip RK3399Pro。</li></ul><p id="12a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mc">敬请关注，不要忘记查看本教程的</em><a class="ae kj" href="https://github.com/Tony607/object_detection_demo" rel="noopener ugc nofollow" target="_blank"><em class="mc">GitHub资源库</em> </a> <em class="mc">和</em><a class="ae kj" href="https://colab.research.google.com/github/Tony607/object_detection_demo/blob/master/tensorflow_object_detection_training_colab.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="mc">Google Colab笔记本</em> </a> <em class="mc">。</em></p></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="7998" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mc">原载于</em><a class="ae kj" href="https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/" rel="noopener ugc nofollow" target="_blank"><em class="mc">www.dlology.com</em></a><em class="mc">。</em></p><figure class="ll lm ln lo fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es nd"><img src="../Images/308a8d84fb9b2fab43d66c117fcc4bb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqDjlKFwScoQYQ62DWEdig.png"/></div></a></figure><h2 id="c148" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">这篇文章发表在<a class="ae kj" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是Medium最大的创业刊物，拥有+423，678名读者。</h2><h2 id="869c" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">在这里订阅接收<a class="ae kj" href="https://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条新闻</a>。</h2><figure class="ll lm ln lo fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es nd"><img src="../Images/b0164736ea17a63403e660de5dedf91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouK9XR4xuNWtCes-TIUNAw.png"/></div></a></figure></div></div>    
</body>
</html>