# 脸书的致命缺陷:剖析

> 原文：<https://medium.com/swlh/the-fatal-flaws-of-facebook-dissected-8285ddf0dd95>

## 如何修复破坏网站的功能

![](img/dcede384d2eed64a079d70046faf75ff.png)

Caspar David Friedrich. *Two Men Contemplating the Moon* (*Zwei Männer betrachten den Mond)*, ca 1830

这一切都是从一种感觉开始的:*我为什么要滚动这个无休止的提要……**我在这里的目的是什么……*在这个社交媒体主导的世界里，这些问题相当于 21 世纪的存在主义危机，人们可能会在萨特的作品中读到这种危机。

随着我开始深入研究，这种最初对脸书核心特征的不安(我后来知道，这也是历史上最有价值的营销工具)演变成了一种痴迷。随着我花更多的时间阅读和分析它，我发现了它的有效性的关键，以及什么会导致最终的审查和信任的丧失，这一直困扰着公司至今。

我仔细分析了这些功能，并了解了是什么让它们如此有效，以及是什么让它们容易被公司本身以及恶意的第三方利用。随着对世界上占主导地位的社交媒体和内容共享平台的内部运作的了解，我也开始反对现状，提出了对这些致命缺陷(或闪光？)来创建一个假设反脸书的框架——一个伦理驱动的社交媒体平台，它不会像脸书允许的那样受到剥削。

以下是这些发现。

## 脸书的致命缺陷#1:推荐算法。

理解脸书的第一步是了解机器学习领域(一种人工智能形式，在过去几年中在科技界风靡一时)。从用户的角度来看，我们知道它是如何工作的，但是他们是如何做到的呢？他们如何不断为我们提供内容，让我们不断回来？

**它是如何工作的？**

没有人真正知道脸书的新闻订阅算法是如何工作的，因为它是完全不透明的。但是我们可以通过与类似结果的[方法](https://applymagicsauce.com/demo)、推荐系统[中可用的研究主体](https://www.computer.org/csdl/journal/tk/2005/06/k0734/13rRUxDIthy)以及公司实体的[专利申请](https://patents.google.com/patent/US20130246521A1)进行比较来猜测他们是如何做到的。

用外行人的话来说，脸书的 a 编辑你“喜欢”的数据，并根据这些内容与什么相关联(什么话题、主题、公司、产品、名人)，它将一组通用标签应用到你的个人资料中。然后，这些标签可以用于向具有相似标签的人呈现相似类型的内容。数据越多，这种标签就越详细，甚至可以预测你的年龄、政治倾向、宗教、性取向、社会地位(收入等级)，甚至智力水平(智商)。难怪广告商如此喜欢脸书。他们的广告工具可以很容易地选择你想要的顾客的标签，所以看到你广告的人有最大的机会购买你的产品。到目前为止，一切顺利(感谢脸书的首席运营官·雪莉·桑德伯格，他是几年前将同样的系统应用于谷歌广告的团队的一员，并被雇来在脸书复制它的成功——谁能想到它会如此顺利呢？).

**但是哪里出了差错呢？**

当人们发现脸书复杂的用户分析系统可以用来销售——不是一个产品——《T4 》,而是一个议程。就在那时。我们都知道那次的[结果。](https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election)

快进到今天，各国政府在敏感时刻关闭了这个平台,因为担心他们会引发大规模的叛乱或起义。这仅仅是开始。

## **脸书的致命缺陷#2:喜欢驱动的评论系统。**

没有用户互动的社交网络是什么？脸书的评论系统提供了类似分形的评论、评论-回复、回复-回复和对每个评论的喜欢。锦上添花的是，当我们看到一大堆通知显示喜欢我们写的东西的人的名单时，我们会肾上腺素激增。

但就一会儿，让我们把自我从等式中去掉。当人们喜欢你的评论时，他们真正在表达什么？如果可以，你会拒绝一个人的喜欢吗？如果你知道这是因为那个人有一个你的评论似乎同意的极端观点，并且那个评论将代表一种信念，然后被用来证明极端主义行为是正当的，即使你最初的评论根本不是由极端的信念驱动的，而只是一个理性的观察，那会怎么样？

好吧，简单点说。社交媒体上的人们并不回避表明立场。我们在 Reddit，Twitter，当然还有脸书上看到它，一个病毒式的帖子表达了一种片面的观点，下面最受欢迎的两条评论完美地代表了每一方的极端观点。问题是，让这些评论像病毒一样传播的不是它们包含的信息，而是它们代表的信念。因此，通过在这样的评论上点击“喜欢”，一个人表达了他们同意评论所代表的一方，而不是理性地评估评论本身的逻辑或事实有效性。正是通过这种方式，脸书的评论系统驱动了一个有毒的病毒式生态系统，在这个系统中，一条内容的轰动效应比其准确性更重要。如果人们可以通过评论或类似的方式表达他们的片面观点，他们的社交媒体使命就完成了——这对平台上的其他人不利。脸书没有采取任何措施来控制可以病毒式传播的内容类型(基于喜欢和评论)，因此，人们继续以获得奖励的方式行事——发布耸人听闻的内容和两极化的评论(因为这些是最受喜欢的)。考虑到这是人类的自然行为，它因此失去了控制。

有什么选择？

为了解决脸书的特征动态在大规模上带来的问题(例如，大众偏执、政治操纵、破坏民主等等)，我们必须从小规模开始——特征调整，以创建一个重视洞察力和准确性而不是哗众取宠和两极分化的平台。

1.  *一个非算法新闻源*——如果你可以简单地查看你的一个朋友在*最近*(你[可以](https://hackernoon.com/escaping-from-cyber-slobdom-3333f83bcc18))发布的所有内容，会怎么样？你可能会对需要滚动浏览的大量内容感到不知所措(尤其是算法推到顶部的*有趣的*内容)。是否存在中间状态(不受算法控制，不完全按时间顺序)？脸书可能希望你不要这样想，因为那样会抹杀它的商业模式。但这肯定是可能的，而且可以说更容易。这需要根据题目和主题来标记内容。与其给你贴上标签，给你提供相应的内容，不如给内容贴上标签，让你在特定时间根据自己的兴趣和心情来管理自己的摄入量。我甚至与人合写了一篇关于它的研究论文。
2.  *非喜欢驱动的评论系统*——平台可以奖励用户对社区的建设性贡献，而不是奖励用户的受欢迎程度(正如我们所知，这不是事实准确性或逻辑的同义词，往往与之相反)。一个平台可以允许评论被“认可”,而不是一个喜欢的系统，本质上是将评论的一些责任不仅放在写评论的人身上，还放在那些选择将自己的名字与评论联系在一起的人身上。人们还可以确定评论的偏见或公正程度，并将中立分数与发布评论的用户相关联。最后，可以通过鼓励引用来评估评论的信息内容，然后可以交叉检查以验证准确性。

尽管如此，我仍然不会告诉你删除你的帐户(尽管如果我是你，我会删除你的帐户)，而是鼓励你更深入地考虑你和其他人在平台上的行为的后果以及他们的动机。不管是否无意，我们都是新的数字信息生态系统的一部分，这个生态系统是[破](https://www.buzzfeednews.com/article/ryanmac/literally-just-a-big-list-of-facebooks-2018-scandals)的。除了个人行为之外，它不会以任何方式改变(因为监管到目前为止肯定没有太大的效果)。