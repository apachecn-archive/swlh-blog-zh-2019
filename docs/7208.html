<html>
<head>
<title>Implementation of Linear Regression 📈</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归的实现📈</h1>
<blockquote>原文：<a href="https://medium.com/swlh/implementation-of-linear-regression-9fd58cb4656c?source=collection_archive---------22-----------------------#2019-06-29">https://medium.com/swlh/implementation-of-linear-regression-9fd58cb4656c?source=collection_archive---------22-----------------------#2019-06-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="781f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">循序渐进的方法</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/7d8500b01d2d85e377fdeed2ca34f305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eLSUnlg0AfLG7DKo.jpeg"/></div></div></figure><p id="13a7" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们将对'<strong class="jl kf"> Boston Housing </strong>'数据集实施线性回归。</p><p id="c7f4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">波士顿数据集包含波士顿不同房屋的信息。该数据集中有506个样本和13个特征变量。我们的目标是<strong class="jl kf">使用给定的特征</strong>预测房子的价格。</p><h2 id="8c44" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated"><strong class="ak">导入必要的库</strong></h2><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="c739" class="kg kh hi lc b fi lg lh l li lj">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span></pre><h2 id="701c" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated"><strong class="ak">将数据集加载到数据框中</strong></h2><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="a862" class="kg kh hi lc b fi lg lh l li lj">data = pd.read_csv("boston.csv")</span></pre><p id="3efa" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">获取关于波士顿住房数据集的基本细节，如空值或缺失值、数据类型等。我们可以用<strong class="jl kf">。info() </strong>如下所示:</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="e0c1" class="kg kh hi lc b fi lg lh l li lj">data.info()</span><span id="ff58" class="kg kh hi lc b fi lk lh l li lj">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 506 entries, 0 to 505<br/>Data columns (total 15 columns):<br/>Unnamed: 0    506 non-null int64<br/>CRIM          506 non-null float64<br/>ZN            506 non-null float64<br/>INDUS         506 non-null float64<br/>CHAS          506 non-null float64<br/>NOX           506 non-null float64<br/>RM            506 non-null float64<br/>AGE           506 non-null float64<br/>DIS           506 non-null float64<br/>RAD           506 non-null float64<br/>TAX           506 non-null float64<br/>PTRATIO       506 non-null float64<br/>B             506 non-null float64<br/>LSTAT         506 non-null float64<br/>target        506 non-null float64<br/>dtypes: float64(14), int64(1)<br/>memory usage: 59.4 KB</span></pre><h2 id="aec6" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">处理数据框中的缺失值</h2><p id="c2e8" class="pw-post-body-paragraph jj jk hi jl b jm ll ij jo jp lm im jr js ln ju jv jw lo jy jz ka lp kc kd ke hb bi translated"><strong class="jl kf">当使用。head()方法:</strong></p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="7978" class="kg kh hi lc b fi lg lh l li lj">data.head()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lq"><img src="../Images/fb929c7d102480644242eb5e0f5402f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/0*m94IuYO1Y8-g6JfZ.png"/></div></figure><p id="7b23" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">通常，<strong class="jl kf"> NaN或缺失值</strong>可以是任何形式，如<strong class="jl kf"> 0、？或者可以写成" missing" </strong>在我们的例子中，我们可以看到有很多0，所以我们可以用NaN代替它们来计算我们丢失了多少数据。</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="148e" class="kg kh hi lc b fi lg lh l li lj">data.ZN.replace(0, np.nan, inplace = True)<br/>data.CHAS.replace(0, np.nan, inplace = True)</span></pre><p id="22c6" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">使用<strong class="jl kf">更换后。info() </strong>方法查看数据集中缺失值的详细信息:</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="b483" class="kg kh hi lc b fi lg lh l li lj">data.info()</span><span id="6110" class="kg kh hi lc b fi lk lh l li lj">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 506 entries, 0 to 505<br/>Data columns (total 15 columns):<br/>Unnamed: 0    506 non-null int64<br/>CRIM          506 non-null float64<br/>ZN            134 non-null float64<br/>INDUS         506 non-null float64<br/>CHAS          35 non-null float64<br/>NOX           506 non-null float64<br/>RM            506 non-null float64<br/>AGE           506 non-null float64<br/>DIS           506 non-null float64<br/>RAD           506 non-null float64<br/>TAX           506 non-null float64<br/>PTRATIO       506 non-null float64<br/>B             506 non-null float64<br/>LSTAT         506 non-null float64<br/>target        506 non-null float64<br/>dtypes: float64(14), int64(1)<br/>memory usage: 59.4 KB</span></pre><p id="a18a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">计算数据集中缺失值的<strong class="jl kf">百分比。一般来说，如果有20-25%的缺失值，我们可以用不同的方法来估算，如均值或中值。</strong></p><p id="f7d9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">但是如果不止如此，最好移除这些特征，否则它们会影响我们的结果。正如我们在下面看到的，<strong class="jl kf">【ZN】</strong>和<strong class="jl kf">【CHAS】</strong>都丢失了超过70%的数据，因此我们将删除这两个特征。</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="0d70" class="kg kh hi lc b fi lg lh l li lj">data.isnull().sum() / len(data) * 100<br/>Unnamed: 0     0.000000<br/>CRIM           0.000000<br/>ZN            73.517787<br/>INDUS          0.000000<br/>CHAS          93.083004<br/>NOX            0.000000<br/>RM             0.000000<br/>AGE            0.000000<br/>DIS            0.000000<br/>RAD            0.000000<br/>TAX            0.000000<br/>PTRATIO        0.000000<br/>B              0.000000<br/>LSTAT          0.000000<br/>target         0.000000<br/>dtype: float64</span></pre><p id="8b50" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">下降列<strong class="jl kf">【ZN】</strong><strong class="jl kf">【CHAS】</strong>以及<strong class="jl kf">【未命名:0】</strong>如下图所示:</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="5a71" class="kg kh hi lc b fi lg lh l li lj">data = data.drop(['ZN', 'CHAS', 'Unnamed: 0'], axis = 1)</span></pre><p id="cee7" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在，再次检查丢失数据的百分比，以确保一切正常，这样我们就可以继续工作，而不用担心丢失数据。</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="26eb" class="kg kh hi lc b fi lg lh l li lj">data.info()<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 506 entries, 0 to 505<br/>Data columns (total 12 columns):<br/>CRIM       506 non-null float64<br/>INDUS      506 non-null float64<br/>NOX        506 non-null float64<br/>RM         506 non-null float64<br/>AGE        506 non-null float64<br/>DIS        506 non-null float64<br/>RAD        506 non-null float64<br/>TAX        506 non-null float64<br/>PTRATIO    506 non-null float64<br/>B          506 non-null float64<br/>LSTAT      506 non-null float64<br/>target     506 non-null float64<br/>dtypes: float64(12)<br/>memory usage: 47.5 KB</span></pre><p id="2a10" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">进一步获得一些关于我们的数据，如平均值，中位数，计数等基本信息。，我们就用<strong class="jl kf">。</strong>描述()方法如下所示:</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="37e7" class="kg kh hi lc b fi lg lh l li lj">data.describe()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lr"><img src="../Images/3ce2a410c945e0426de81de4b0f72346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NMxWDIK-OoHLp7C5.png"/></div></div></figure><h2 id="b537" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated"><strong class="ak">分离因变量和自变量</strong></h2><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="715f" class="kg kh hi lc b fi lg lh l li lj">X = data.iloc[:,:-1]<br/>y = data.iloc[:,-1]</span></pre><h2 id="07f7" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated"><strong class="ak">将数据分为训练集和测试集</strong></h2><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="ebef" class="kg kh hi lc b fi lg lh l li lj">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)</span></pre><h2 id="eeaf" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated"><strong class="ak">从sklearn导入线性回归类</strong></h2><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="0b2b" class="kg kh hi lc b fi lg lh l li lj">from sklearn.linear_model import LinearRegression<br/>model = LinearRegression()<br/>model.fit(X_train, y_train) # Fitting our model to the training set</span></pre><h2 id="5e23" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated"><strong class="ak">现在用做预测。预测()方法</strong></h2><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="e730" class="kg kh hi lc b fi lg lh l li lj">y_pred = model.predict(X_test)</span></pre><h2 id="d448" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated"><strong class="ak">计算衡量模型性能的指标</strong></h2><p id="ad46" class="pw-post-body-paragraph jj jk hi jl b jm ll ij jo jp lm im jr js ln ju jv jw lo jy jz ka lp kc kd ke hb bi translated">这里我们计算了<strong class="jl kf">平均绝对误差(MAE)、均方误差(MSE)和均方根误差(RMSE) </strong>。我们还为我们的分类器计算了<strong class="jl kf">分数</strong>。</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="429d" class="kg kh hi lc b fi lg lh l li lj">from sklearn import metrics <br/>print("MAE", metrics.mean_absolute_error(y_test, y_pred))<br/>print("MSE", metrics.mean_squared_error(y_test, y_pred))<br/>print("RMSE", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))<br/>print("Score:", model.score(X_test, y_test))</span><span id="0985" class="kg kh hi lc b fi lk lh l li lj">MAE 3.773568493778742<br/>MSE 31.332023490151126<br/>RMSE 5.59750153998649<br/>Score: 0.6164944788849184</span></pre><p id="2629" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们也在测试集和预测集上做一个散点图，在理想情况下应该沿着一条直线。</p><pre class="iy iz ja jb fd lb lc ld le aw lf bi"><span id="15cc" class="kg kh hi lc b fi lg lh l li lj">plt.scatter(y_pred, y_test)<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ls"><img src="../Images/669d750c8fef03ab38418d731ab0f5be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/0*DPUma8qgewKJjlTY"/></div></div></figure><p id="e865" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这是一个很好的结果，但您永远不会以这种方式对波士顿住房数据集使用线性回归，我们通常会使用正则化来进一步约束模型系数。</p><p id="4da8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">好了，伙计们，你们已经学会了如何对“波士顿住房”数据集进行线性回归。现在，继续尝试在您选择的任何数据集上实现线性回归。</p></div></div>    
</body>
</html>